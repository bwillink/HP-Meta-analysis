(dat$N_C[i] - dat$Success_C[i]) > 0 &
(dat$N_X[i] - dat$Success_X[i]) > 0) {
dat$OR[i] <-
(dat$Success_X[i] * (dat$N_C[i] - dat$Success_C[i])) / (dat$Success_C[i] * (dat$N_X[i] - dat$Success_X[i]))
dat$Log.OR[i] <- log(dat$OR[i])
# approximate variance
dat$Log.OR.v[i] <-
1 / dat$Success_X[i] + 1 / (dat$N_X[i] - dat$Success_X[i]) + 1 / dat$Success_C[i] + 1 / (dat$N_C[i] - dat$Success_C[i])
}
else {
# if at least one category is 0, we apply Yate's correction to avoid dividing by 0
if (dat$Variation.Type[i] == "OR" &
(dat$Success_C[i] == 0 |
dat$Success_X[i] == 0 |
(dat$N_C[i] - dat$Success_C[i]) == 0 |
(dat$N_X[i] - dat$Success_X[i]) == 0)) {
dat$OR[i] <-
((dat$Success_X[i] + 0.5) * (dat$N_C[i] - dat$Success_C[i] + 0.5)) / ((dat$Success_C[i] + 0.5) * (dat$N_X[i] - dat$Success_X[i] + 0.5))
dat$Log.OR[i] <- log(dat$OR[i])
# approximate variance
dat$Log.OR.v[i] <-
1 / (dat$Success_X[i] + 0.5)  + 1 / (dat$N_X[i] - dat$Success_X[i] + 0.5) + 1 / (dat$Success_C[i] + 0.5) + 1 / (dat$N_C[i] - dat$Success_C[i] + 0.5)
}
else{
# if there is no OR data, make these columns NA
dat$OR[i] <- NA
dat$Log.OR[i] <- NA
dat$Log.OR.v[i] <- NA
}
}
}
# create SD variables
dat$SD_C <- vector(length = N)
dat$SD_X <- vector(length = N)
for (i in 1:N) {
# Calculate SD if SE is reported
if (dat$Variation.Type[i] == "SE") {
dat$SD_C[i] <- dat$Variation_C[i] * sqrt(dat$N_C[i])
dat$SD_X[i] <- dat$Variation_X[i] * sqrt(dat$N_X[i])
} else {
# calculate SD if a 95% confidence interval for a normal distribution is reported
# this also applies to the Wald confidence interval for proportions, as it is a normal approximation to the binomial
if (dat$Variation.Type[i] == "CI" |
dat$Variation.Type[i] == "Wald CI") {
# calculate SE from lower and upper limits
temp_C1 <- (dat$Upr_C[i] - dat$Mean_C[i]) / 1.96
temp_C2 <- (dat$Mean_C[i] - dat$Lwr_C[i]) / 1.96
temp_X1 <- (dat$Upr_X[i] - dat$Mean_X[i]) / 1.96
temp_X2 <- (dat$Mean_X[i] - dat$Lwr_X[i]) / 1.96
# average digitized/recorded values of SE (because we have two) and transform to SD
dat$SD_C[i] <-
mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_C[i])
dat$SD_X[i] <-
mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_X[i])
} else {
# approximate SD if IQ range is reported
if (dat$Variation.Type[i] == "IQ") {
dat$SD_C[i] <- (dat$Upr_C[i] - dat$Lwr_C[i]) / 1.35
dat$SD_X[i] <- (dat$Upr_X[i] - dat$Lwr_X[i]) / 1.35
}
else {
# if SD is reported leave as such
if (dat$Variation.Type[i] == "SD") {
dat$SD_C[i] <- dat$Variation_C[i]
dat$SD_X[i] <- dat$Variation_X[i]
} else {
# if there is no appropriate data, make these columns NA
dat$SD_C[i] <- NA
dat$SD_X[i] <- NA
}
}
}
}
}
# within groups standard deviation
dat$S_within <-
sqrt(((dat$N_C - 1) * dat$SD_C ^ 2 + (dat$N_X - 1) * dat$SD_X ^ 2) / (dat$N_C + dat$N_X - 2))
# standardized effect size
for (i in 1:N) {
# standardized mean difference
# we can't include data without variance
if (is.na(dat$S_within[i]) == FALSE & dat$S_within[i] > 0) {
dat$d[i] <- (dat$Mean_X[i] - dat$Mean_C[i]) / dat$S_within[i]
dat$var.d[i] <-
(dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
(2 * (dat$N_C[i] + dat$N_X[i]))
}
else{
# if only F statistic is reported - no cases of this yet!
if (dat$Variation.Type[i] == "F_X") {
dat$d[i] <-
sqrt(dat$F_X[i] * (dat$N_X[i] + dat$N_C[i]) / (dat$N_C[i] * dat$N_X[i]))
dat$var.d[i] <-
(dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
(2 * (dat$N_C[i] + dat$N_X[i]))
} else{
# if Z and N are reported for a regression analysis
if (dat$Variation.Type[i] == "Z_reg") {
r <- dat$Z_X[i] / sqrt(dat$Z_N[i])
dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
Vr <- (1 - r ^ 2) ^ 2 / (dat$Z_N[i] - 1)
dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
}
else{
# if t and N are reported for a regression analysis
if (dat$Variation.Type[i] == "t") {
r <- sqrt((dat$Z_X[i] ^ 2) / (dat$Z_X[i] ^ 2 + dat$Z_df[i]))
dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
Vr <- (1 - r ^ 2) ^ 2 / (dat$R_N[i] - 1)
dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
}
else{
# If Z is reported from a comparison of two independent groups
if (dat$Variation.Type[i] == "Z") {
dat$d[i] <-
sqrt(abs(dat$Z_X[i]) * sqrt(dat$N_C[i] + dat$N_X[i]) / (1 - sqrt(
dat$Z_X[i] ^ 2 * (dat$N_C[i] + dat$N_X[i]) ^ -1
)))
dat$var.d[i] <-
(dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
(2 * (dat$N_C[i] + dat$N_X[i]))
}
else{
# converting log OR
if (is.na(dat$Log.OR.v[i]) == FALSE &
dat$Log.OR.v[i] > 0) {
dat$d[i] <- dat$Log.OR[i] * (sqrt(3) / pi)
dat$var.d[i] <- dat$Log.OR.v[i] * 3 / pi ^ 2
} else {
# for now, leave other types of effects as NA
dat$d[i] <- NA
dat$var.d[i] <- NA
}
}
}
}
}
}
}
# sample size correction factor
for (i in 1:N) {
# if odds ratio or comparison between means
if (is.na(dat$N_C[i]) == F) {
dat$J[i] <- 1 - 3 / (4 * (dat$N_C[i] + dat$N_X[i] - 2) - 1)
} else {
# if correlation
if (is.na(dat$R_N[i]) == F) {
dat$J[i] <- 1 - 3 / (4 * (dat$R_N[i] - 2) - 1)
}else {
dat$J[i] <- NA
}
}
}
# corrected effect size
dat$g <- dat$J * dat$d
# and variance
dat$var.g <- (dat$J ^ 2) * dat$var.d
mort <- grep(pattern = "[M,m]ort", x = dat$Trait)
for(i in mort){
dat$g[i] <- -dat$g[i]
}
# For now, get rid of NAs
dat <- dat[(is.na(dat$d) == F),]
# How many experiments do we have?
Exps <- unique(dat$Experiment)
# A data frame of experiments that included Infected demographic and Uninfected demographic effects
dat_1 <- data.frame()
# A data frame of experiments that included Infected demographic and Epidemiological effects
dat_3 <- data.frame()
# populate data sets with corresponding experiments
for (i in Exps) {
tmp <- dat[which(dat$Experiment == i), ]
if ("Uninfected demographic" %in% tmp$Trait.category &
"Infected demographic" %in% tmp$Trait.category) {
dat_1 <- rbind(dat_1, tmp)
}
if ("Epidemiological" %in% tmp$Trait.category &
"Infected demographic" %in% tmp$Trait.category) {
dat_3 <- rbind(dat_3, tmp)
}
}
dat_1 <- dat_1[which(dat_1$Trait.category == "Uninfected demographic" | dat_1$Trait.category == "Infected demographic"),]
dat_3 <- dat_3[which(dat_3$Trait.category == "Epidemiological" | dat_3$Trait.category == "Infected demographic"),]
# A data frame with experiments that include just epidemiological effects
dat_2 <- dat_3[which(dat_3$Trait.category == "Epidemiological"),]
studies_1 <- unique(dat_1$Study)
studies_to_check <- c()
negative_eigen <- c()
for (k in studies_1) {
dat_study <- dat_1[which(dat_1$Study == k),]
varcovmat = matrix(0,
nrow = dim(dat_study)[1],
ncol = dim(dat_study)[1])
for (i in 1:dim(dat_study)[1]) {
for (j in 1:dim(dat_study)[1]) {
if (i == j) {
varcovmat[i, j] = dat_study$var.g[i]
} else{
if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
dat_study[i, "Trait"] == dat_study[j, "Trait"] &
dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
(dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
}
}
}
}
val <- eigen(varcovmat)
for (m in 1:length(val$values)) {
if (val$values[m] < 0) {
studies_to_check <- append(studies_to_check, k)
negative_eigen <- append(negative_eigen, val$values[m])
}
}
}
Neg_eigen_1 <- data.frame(study = studies_to_check, eigen = negative_eigen)
Neg_eigen_1 %>%
kbl() %>%
kable_material(c("striped", "hover"), full_width = F)
studies_2 <- unique(dat_2$Study)
studies_to_check <- c()
negative_eigen <- c()
for (k in studies_2) {
dat_study <- dat_2[which(dat_2$Study == k),]
varcovmat = matrix(0,
nrow = dim(dat_study)[1],
ncol = dim(dat_study)[1])
for (i in 1:dim(dat_study)[1]) {
for (j in 1:dim(dat_study)[1]) {
if (i == j) {
varcovmat[i, j] = dat_study$var.g[i]
} else{
if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
dat_study[i, "Trait"] == dat_study[j, "Trait"] &
dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
(dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
}
}
}
}
val <- eigen(varcovmat)
for (m in 1:length(val$values)) {
if (val$values[m] < 0) {
studies_to_check <- append(studies_to_check, k)
negative_eigen <- append(negative_eigen, val$values[m])
}
}
}
Neg_eigen_2 <- data.frame(study = studies_to_check, eigen = negative_eigen)
Neg_eigen_2 %>%
kbl() %>%
kable_material(c("striped", "hover"), full_width = F)
studies_3 <- unique(dat_3$Study)
studies_to_check <- c()
negative_eigen <- c()
for (k in studies_3) {
dat_study <- dat_3[which(dat_3$Study == k),]
varcovmat = matrix(0,
nrow = dim(dat_study)[1],
ncol = dim(dat_study)[1])
for (i in 1:dim(dat_study)[1]) {
for (j in 1:dim(dat_study)[1]) {
if (i == j) {
varcovmat[i, j] = dat_study$var.g[i]
} else{
if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
dat_study[i, "Trait"] == dat_study[j, "Trait"] &
dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
(dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
}
}
}
}
val <- eigen(varcovmat)
for (m in 1:length(val$values)) {
if (val$values[m] < 0) {
studies_to_check <- append(studies_to_check, k)
negative_eigen <- append(negative_eigen, val$values[m])
}
}
}
Neg_eigen_3 <- data.frame(study = studies_to_check, eigen = negative_eigen)
Neg_eigen_3 %>%
kbl() %>%
kable_material(c("striped", "hover"), full_width = F)
# exclude suspicious studies with highly negative eigenvalues
dat_1 <- dat_1[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_1$Study),]
dat_1 <- dat_1[-grep("Shostak et al. 2015. Journal of Parasitology", dat_1$Study),]
dat_1 <- dat_1[-grep(121, dat_1$Experiment),]
varcovmat_1 = matrix(0, nrow = dim(dat_1)[1], ncol = dim(dat_1)[1])
for (i in 1:dim(dat_1)[1]) {
for (j in 1:dim(dat_1)[1]) {
if (i == j) {varcovmat_1[i,j] = dat_1$var.g[i]}else{
if (dat_1[i, "Experiment"] == dat_1[j, "Experiment"] & dat_1[i, "Level_C"] == dat_1[j, "Level_C"] & dat_1[i, "Trait"] == dat_1[j, "Trait"] & dat_1[i, "Trait.category"] == dat_1[j, "Trait.category"]) {
varcovmat_1[i,j] = 1/dat_1[i,"N_C"] + dat_1$g[i]*dat_1$g[j]/(dat_1[i,"N_C"] + dat_1[i,"N_X"] + dat_1[j,"N_X"])
}
}
}
}
# correct negative eigens in the few studies with large covar to var ratios
varcovmat_1_PD <- nearPD(varcovmat_1,  keepDiag = TRUE)
# exclude suspicious studies with highly negative eigenvalues
dat_2 <- dat_2[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_2$Study),]
varcovmat_2 = matrix(0, nrow = dim(dat_2)[1], ncol = dim(dat_2)[1])
for (i in 1:dim(dat_2)[1]) {
for (j in 1:dim(dat_2)[1]) {
if (i == j) {varcovmat_2[i,j] = dat_2$var.g[i]}else{
if (dat_2[i, "Experiment"] == dat_2[j, "Experiment"] & dat_2[i, "Level_C"] == dat_2[j, "Level_C"] & dat_2[i, "Trait"] == dat_2[j, "Trait"] & dat_2[i, "Trait.category"] == dat_2[j, "Trait.category"]) {
varcovmat_2[i,j] = 1/dat_2[i,"N_C"] + dat_2$g[i]*dat_2$g[j]/(dat_2[i,"N_C"] + dat_2[i,"N_X"] + dat_2[j,"N_X"])
}
}
}
}
# correct negative eigens in the few studies with large covar to var ratios
varcovmat_2_PD <- nearPD(varcovmat_2,  keepDiag = TRUE)
# exclude suspicious studies with highly negative eigenvalues
dat_3 <- dat_3[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_3$Study),]
# Carrington et al. 2013 has extremely large sampling variance for a parasite prevalence effect. DOUBLE CHECK!!!
dat_3 <- dat_3[-grep("Carrington et al. 2013. PLOS NegTropDiseases", dat_3$Study),]
varcovmat_3 = matrix(0, nrow = dim(dat_3)[1], ncol = dim(dat_3)[1])
for (i in 1:dim(dat_3)[1]) {
for (j in 1:dim(dat_3)[1]) {
if (i == j) {varcovmat_3[i,j] = dat_3$var.g[i]}else{
if (dat_3[i, "Experiment"] == dat_3[j, "Experiment"] & dat_3[i, "Level_C"] == dat_3[j, "Level_C"] & dat_3[i, "Trait"] == dat_3[j, "Trait"] & dat_3[i, "Trait.category"] == dat_3[j, "Trait.category"]) {
varcovmat_3[i,j] = 1/dat_3[i,"N_C"] + dat_3$g[i]*dat_3$g[j]/(dat_3[i,"N_C"] + dat_3[i,"N_X"] + dat_3[j,"N_X"])
}
}
}
}
# correct eigenvalues in the few studies with large covar to var ratios
varcovmat_3_PD <- nearPD(varcovmat_3, keepDiag = TRUE)
# For now remove rare host types to check interaction with host
dat_3_byHost <- dat_3[which(dat_3$Host.type == "Arthropod" | dat_3$Host.type == "Mollusc" | dat_3$Host.type == "Fish" | dat_3$Host.type == "Amphibian"), ]
varcovmat_3_byHost = matrix(0, nrow = dim(dat_3_byHost)[1], ncol = dim(dat_3_byHost)[1])
for (i in 1:dim(dat_3_byHost)[1]) {
for (j in 1:dim(dat_3_byHost)[1]) {
if (i == j) {varcovmat_3_byHost[i,j] = dat_3_byHost$var.g[i]}else{
if (dat_3_byHost[i, "Experiment"] == dat_3_byHost[j, "Experiment"] & dat_3_byHost[i, "Level_C"] == dat_3_byHost[j, "Level_C"] & dat_3_byHost[i, "Trait"] == dat_3_byHost[j, "Trait"] & dat_3_byHost[i, "Trait.category"] == dat_3_byHost[j, "Trait.category"]) {
varcovmat_3_byHost[i,j] = 1/dat_3_byHost[i,"N_C"] + dat_3_byHost$g[i]*dat_3_byHost$g[j]/(dat_3_byHost[i,"N_C"] + dat_3_byHost[i,"N_X"] + dat_3_byHost[j,"N_X"])
}
}
}
}
# correct eigenvalues in the few studies with large covar to var ratios
varcovmat_3_byHost_PD <- nearPD(varcovmat_3_byHost,  keepDiag = TRUE)
dat_1 <- mutate(dat_1, Host.type.2 = case_when(
Host.type == "Fish" ~ "Vertebrate",
Host.type == "Arthropod" ~ "Invertebrate",
Host.type == "Amphibian" ~ "Vertebrate",
Host.type == "Mollusc" ~ "Invertebrate"))
dat_2 <- mutate(dat_2, Host.type.2 = case_when(
Host.type == "Fish" ~ "Vertebrate",
Host.type == "Arthropod" ~ "Invertebrate",
Host.type == "Amphibian" ~ "Vertebrate",
Host.type == "Mollusc" ~ "Invertebrate",
Host.type == "Reptile" ~ "Vertebrate",
Host.type == "Bird" ~ "Vertebrate",
Host.type == "Mammal" ~ "Vertebrate"))
dat_3 <- mutate(dat_3, Host.type.2 = case_when(
Host.type == "Fish" ~ "Vertebrate",
Host.type == "Arthropod" ~ "Invertebrate",
Host.type == "Amphibian" ~ "Vertebrate",
Host.type == "Mollusc" ~ "Invertebrate",
Host.type == "Reptile" ~ "Vertebrate",
Host.type == "Bird" ~ "Vertebrate",
Host.type == "Mammal" ~ "Vertebrate"))
# First, we evaluate some code that generates helper functions needed so that metafor and MuMIn could interact as necessary
eval(metafor:::.MuMIn)
# Now, we take the full model (in this case Q2m4) and fit the rest of the models and examine those models whose AICc value is no more than 2 units away from that of the best model
full_model.1 <- rma.mv(
g,
V = varcovmat_1_PD$mat,
mods = ~ Trait.category*Trait.type*Gradient.category,
random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
data = dat_1,
method = "ML"
)
model_selection.1 <- dredge(full_model.1, trace = 2)
subset(model_selection.1, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method
# Multimodel inference
average.model.1 <- model.avg(model_selection.1, revised.var=FALSE)
summary(average.model.1) #Set revised.var = F to get same results as we would with the glmulti package
# relative importance values for the predictors can be obtained with:
importance(model_selection.1)
# Best model Q1m4
# Define a function that takes a model formula and a dataset as input and then fits a random/mixed-effects meta-regression model to the given data using maximum likelihood estimation (to compare models we have to use ML, and then we can re-fit with REML)
rma.glmulti <- function(formula, data, V, random, ...){
rma.mv(formula, V = V, data = data, random = random, method="ML", ...)
}
# Fit all models
all.models.2 <- glmulti(g ~ Trait.type*Gradient.category,
data=dat_2,
V = varcovmat_2_PD$mat,
random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
level = 2, fitfunction = rma.glmulti, crit="aicc", marginality = TRUE)
# --> Tried "intercept = F", to exclude the intercept from  the candidate models, and got "Error in x[, ii] : subscript out of bounds"
# summary
print(all.models.2)
# plot of AICc values for the models. The line separates the models that are less or more that 2 units away from the best model
plot(all.models.2)
# Top models
top.models.2 <- weightable(all.models.2)
top.models.2 <- top.models.2[top.models.2$aicc <= min(top.models.2$aicc) + 2,]
top.models.2
# Variable importance plot across all the models
plot(all.models.2, type="s")
# --> none of them reach >= 0.8
#Multimodel inference - make inferences about various predictors across all possible models relative to their weights
#To get the glmulti package to handle rma.uni objects, we must register a getfit method for such objects
eval(metafor:::.glmulti)
coef(all.models.2)
# Organized table, getting the unconditional estimates
mmi.2 <- as.data.frame(coef(all.models.2))
mmi.2 <- data.frame(Estimate=mmi.2$Est, SE=sqrt(mmi.2$Uncond), Importance=mmi.2$Importance, row.names=row.names(mmi.2))
mmi.2$z <- mmi.2$Estimate / mmi.2$SE
mmi.2$p <- 2*pnorm(abs(mmi.2$z), lower.tail=FALSE)
names(mmi.2) <- c("Estimate", "Std. Error", "Importance", "z value", "Pr(>|z|)")
mmi.2$ci.lb <- mmi.2[[1]] - qnorm(.975) * mmi.2[[2]]
mmi.2$ci.ub <- mmi.2[[1]] + qnorm(.975) * mmi.2[[2]]
mmi.2 <- mmi.2[order(mmi.2$Importance, decreasing=TRUE), c(1,2,4:7,3)]
round(mmi.2, 4)
#Multimodel predictions
# --> Note: how (and when) can we re-fit the model with REML?
#           how do we deal with interactions?
# x <- data.frame("Gradient.category" = c("Environment", "Pollution", "Resource", "Environment", "Pollution", "Resource"), "Trait.type" = c("Intensity", "Intensity", "Intensity", "Prevalence", "Prevalence", "Prevalence"))
# predict.glmulti(res, varweighting = "Buckland", newdata = x, icmethod = "Lukacs", se.fit = TRUE)
preds <- list()
x <- c("Gradient.categoryPollution" = T, "Gradient.categoryResource" = F, "Trait.typePrevalence" = T, "Gradient.categoryEnvironment:Trait.typeIntensity" = F, "Gradient.categoryPollution:Trait.typeIntensity" = F,
"Gradient.categoryResource:Trait.typeIntensity" = F, "Gradient.categoryEnvironment:Trait.typePrevalence" = F,
"Gradient.categoryPollution:Trait.typePrevalence" = F,
"Gradient.categoryResource:Trait.typePrevalence" = F,
"Trait.typePrevalence:Gradient.categoryResource" = F,
"Trait.typePrevalence:Gradient.categoryPollution" = F,
"Trait.typePrevalence:Gradient.categoryEnvironment" = F,
"Trait.typeIntensity:Gradient.categoryResource" = F,
"Trait.typeIntensity:Gradient.categoryPollution" = F,
"Trait.typeIntensity:Gradient.categoryEnvironment" = F)
#Missing Gradient.categoryEnvironment and Trait.typeIntensity
for (j in 1:all.models.2@nbmods) {
model <- all.models.2@objects[[j]]
vars <- names(coef(model))[-1]
if (length(vars) == 0) {
preds[[j]] <- predict(model)
} else {
preds[[j]] <- predict(model, newmods=x[vars])
}
}
weights <- weightable(all.models)$weights
weights <- weightable(all.models.2)$weights
yhat <- sum(weights * sapply(preds, function(x) x$pred))
round(yhat, 3)
se <- sqrt(sum(weights * sapply(preds, function(x) x$se^2 + (x$pred - yhat)^2)))
round(yhat + c(-1,1)*qnorm(.975)*se, 3)
# Now, we take the full model and fit the rest of the models and examine those models whose AICc value is no more than 10 units away from that of the best model
full_model.2 <- rma.mv(
g,
V = varcovmat_2_PD$mat,
mods = ~ Trait.type * Gradient.category,
random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
data = dat_2,
method = "ML"
)
model_selection.2 <- dredge(full_model.2, trace = 2)
subset(model_selection.2, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method
# Multimodel inference
average.model.2 <- model.avg(model_selection.2, revised.var=FALSE)
summary(average.model.2) #Set revised.var = F to get same results as we would with the glmulti package
# relative importance values for the predictors can be obtained with:
importance(model_selection.2)
#How do we get model predictions? - Still not working
predict(average.model.2, se.fit = T)
full_model.3 <- rma.mv(
g,
V = varcovmat_3_PD$mat,
mods = ~ Trait.type*Gradient.category,
random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
data = dat_3,
method = "ML"
)
# Define if using Trait.type or Trait.category
model_selection.3 <- dredge(full_model.3, trace = 2)
subset(model_selection.3, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method
# Multimodel inference
average.model.3 <- model.avg(model_selection.3, revised.var=FALSE)
summary(average.model.3) #Set revised.var = F to get same results as we would with the glmulti package
# relative importance values for the predictors can be obtained with:
importance(model_selection.3)
#Best model Q3m4
# relative importance values for the predictors can be obtained with:
importance(model_selection.2)
# relative importance values for the predictors can be obtained with:
importance(model_selection.1)
model_selection.1
# relative importance values for the predictors can be obtained with:
importance(model_selection.3)
model_selection.3
model_selection.1
# relative importance values for the predictors can be obtained with:
importance(model_selection.1)
# relative importance values for the predictors can be obtained with:
importance(model_selection.3)
model_selection.3
# relative importance values for the predictors can be obtained with:
importance(model_selection.2)
