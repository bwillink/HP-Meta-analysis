---
title: "Host-Parasite Meta-analysis"
author: "Amanda Vicente, Beatriz Willink, Kacy Nowak, Dave Civitello"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    number_sections: false
    toc: true
    toc_float: true
    toc_depth: 4
---

Load packages
```{r load-packages, message=FALSE, results='hide'}
x <-
  c(
    "metafor", "kableExtra", "Matrix", "dplyr", "wesanderson", "weightr", "ggplot2", "MuMIn", "glmulti")

lapply(x, function(y) {
  # check if installed, if not install
  if (!y %in% installed.packages()[, "Package"])
    install.packages(y)
  
  # load package
  try(require(y, character.only = T), silent = T)
})
```
*Note* If you have trouble loading the glmulti package due to issues with Java, follow https://zhiyzuo.github.io/installation-rJava/ using the version Java17 (make sure to download the Arm 64 DMG Installer at https://www.oracle.com/java/technologies/downloads/#jdk17-mac)

Read in data
```{r read-data}
dat <- read.csv("../data/MA_dat_08-05-2021.csv", header = T, sep = ",")

# subset data that have a "variation type". We'll parse based on variation type below
#dat <- dat[-which(is.na(dat$Variation.Type) == TRUE),]
dat <- subset(dat, select = -c(Data_source,Comment)) 
colnames(dat)
  
```

# Data cleaning
*There might be more of this coming...*

## Gradient categories 
```{r}
# Toxin is a type of pollution
dat$Gradient.category <- gsub(pattern = "Toxin", replacement = "Pollution", x = dat$Gradient.category)

# exclude ambiguous/equivocal categories
dat <- dat[which(dat$Gradient.category != "Ecological"),]

# Check gradient categories 
levels(as.factor(dat$Gradient.category))
```

## Median, min, max and n to mean and SD
```{r}
non_par <- dat[which(dat$Variation.Type == "Median_Min_Max"),]

# Estimate mean for control and treatment from median, maximum and minimum
non_par$Estimated_Mean_C <- (non_par$Lwr_C + 2 * non_par$Mean_C + non_par$Upr_C) / 4
non_par$Estimated_Mean_X <- (non_par$Lwr_X + 2 * non_par$Mean_X + non_par$Upr_X) / 4

# Estimate SD from range and n
# First, read in Xi_N table from Wang et al. (2014) BMC Medical Research Methodology
Xi_table <- read.csv("../scripts/Xi_N_Table.csv", header = T, sep = ",") 

# Estimate SD using the approximation for each N under 50
for (i in 1:length(non_par$ID)) {
  non_par$Estimated_SD_C[i] <-
    (non_par$Upr_C[i] - non_par$Lwr_C[i]) / Xi_table$Xi_N[which(Xi_table$N == non_par$N_C[i])]
  non_par$Estimated_SD_X[i] <-
    (non_par$Upr_X[i] - non_par$Lwr_X[i]) / Xi_table$Xi_N[which(Xi_table$N == non_par$N_X[i])]
}

# overwrite dat
dat$Mean_C[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_Mean_C 
dat$Mean_X[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_Mean_X

dat$Variation_C[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_SD_C
dat$Variation_X[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_SD_X

dat$Variation.Type[which(dat$Variation.Type == "Median_Min_Max")] <- "SD"

# Sanity check
levels(as.factor(dat$Variation.Type))
```

## Median and IQ range to mean 
```{r}
non_par <- dat[which(dat$Variation.Type == "Median_IQ"),]

# Estimate mean for control and treatment from median and IQ range
non_par$Estimated_Mean_C <- (non_par$Lwr_C + non_par$Mean_C + non_par$Upr_C) / 3
non_par$Estimated_Mean_X <- (non_par$Lwr_X + non_par$Mean_X + non_par$Upr_X) / 3

# overwrite dat
dat$Mean_C[which(dat$Variation.Type == "Median_IQ")] <- non_par$Estimated_Mean_C 
dat$Mean_X[which(dat$Variation.Type == "Median_IQ")] <- non_par$Estimated_Mean_X

dat$Variation.Type[which(dat$Variation.Type == "Median_IQ")] <- "IQ"

# Sanity check
levels(as.factor(dat$Variation.Type))
```

## subset effects with workable "variation types"
```{r}
nrow(dat)

accepted_var <- c("SE", "SD", "CI", "Wald CI", "IQ", "OR")
dat <- dat[which(dat$Variation.Type %in% accepted_var),]

nrow(dat)

# store sample size in an object
N <- nrow(dat)
```

# Getting effect sizes

## Calculate OR and approximate variance from contingency tables
```{r OR}
for (i in 1:N) {
  # no correction need if none of the categories are 0
  if (dat$Variation.Type[i] == "OR" &
      dat$Success_C[i] > 0 &
      dat$Success_X[i] > 0 &
      (dat$N_C[i] - dat$Success_C[i]) > 0 &
      (dat$N_X[i] - dat$Success_X[i]) > 0) {
    dat$OR[i] <-
      (dat$Success_X[i] * (dat$N_C[i] - dat$Success_C[i])) / (dat$Success_C[i] * (dat$N_X[i] - dat$Success_X[i]))
    dat$Log.OR[i] <- log(dat$OR[i])
    # approximate variance
    dat$Log.OR.v[i] <-
      1 / dat$Success_X[i] + 1 / (dat$N_X[i] - dat$Success_X[i]) + 1 / dat$Success_C[i] + 1 / (dat$N_C[i] - dat$Success_C[i])
  }
  else {
    # if at least one category is 0, we apply Yate's correction to avoid dividing by 0
    if (dat$Variation.Type[i] == "OR" &
        (dat$Success_C[i] == 0 |
        dat$Success_X[i] == 0 |
        (dat$N_C[i] - dat$Success_C[i]) == 0 |
        (dat$N_X[i] - dat$Success_X[i]) == 0)) {
      dat$OR[i] <-
        ((dat$Success_X[i] + 0.5) * (dat$N_C[i] - dat$Success_C[i] + 0.5)) / ((dat$Success_C[i] + 0.5) * (dat$N_X[i] - dat$Success_X[i] + 0.5))
      dat$Log.OR[i] <- log(dat$OR[i])
      # approximate variance
      dat$Log.OR.v[i] <-
        1 / (dat$Success_X[i] + 0.5)  + 1 / (dat$N_X[i] - dat$Success_X[i] + 0.5) + 1 / (dat$Success_C[i] + 0.5) + 1 / (dat$N_C[i] - dat$Success_C[i] + 0.5)
    }
    else{
      # if there is no OR data, make these columns NA
      dat$OR[i] <- NA
      dat$Log.OR[i] <- NA
      dat$Log.OR.v[i] <- NA
    }
  }
}
```


## Calculate SD for comparisons with continuous normally distributed variables
```{r SD}
# create SD variables
dat$SD_C <- vector(length = N)
dat$SD_X <- vector(length = N)

for (i in 1:N) {
  # Calculate SD if SE is reported
  if (dat$Variation.Type[i] == "SE") {
    dat$SD_C[i] <- dat$Variation_C[i] * sqrt(dat$N_C[i])
    dat$SD_X[i] <- dat$Variation_X[i] * sqrt(dat$N_X[i])
  } else {
    # calculate SD if a 95% confidence interval for a normal distribution is reported
    # this also applies to the Wald confidence interval for proportions, as it is a normal approximation to the binomial
    if (dat$Variation.Type[i] == "CI" |
        dat$Variation.Type[i] == "Wald CI") {
      # calculate SE from lower and upper limits
      temp_C1 <- (dat$Upr_C[i] - dat$Mean_C[i]) / 1.96
      temp_C2 <- (dat$Mean_C[i] - dat$Lwr_C[i]) / 1.96
      
      temp_X1 <- (dat$Upr_X[i] - dat$Mean_X[i]) / 1.96
      temp_X2 <- (dat$Mean_X[i] - dat$Lwr_X[i]) / 1.96
      
      # average digitized/recorded values of SE (because we have two) and transform to SD
      dat$SD_C[i] <-
        mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_C[i])
      dat$SD_X[i] <-
        mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_X[i])
    } else {
      # approximate SD if IQ range is reported
      if (dat$Variation.Type[i] == "IQ") {
        dat$SD_C[i] <- (dat$Upr_C[i] - dat$Lwr_C[i]) / 1.35
        dat$SD_X[i] <- (dat$Upr_X[i] - dat$Lwr_X[i]) / 1.35
      }
      else {
        # if SD is reported leave as such
        if (dat$Variation.Type[i] == "SD") {
          dat$SD_C[i] <- dat$Variation_C[i]
          dat$SD_X[i] <- dat$Variation_X[i]
        } else {
          # if there is no appropriate data, make these columns NA
          dat$SD_C[i] <- NA
          dat$SD_X[i] <- NA
        }
      }
    }
  }
}
```


## Get effect sizes and variances
```{r calculate d}
# within groups standard deviation
dat$S_within <-
  sqrt(((dat$N_C - 1) * dat$SD_C ^ 2 + (dat$N_X - 1) * dat$SD_X ^ 2) / (dat$N_C + dat$N_X - 2))

# standardized effect size
for (i in 1:N) {
  # standardized mean difference
  # we can't include data without variance
  if (is.na(dat$S_within[i]) == FALSE & dat$S_within[i] > 0) {
    dat$d[i] <- (dat$Mean_X[i] - dat$Mean_C[i]) / dat$S_within[i]
    dat$var.d[i] <-
      (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
      (2 * (dat$N_C[i] + dat$N_X[i]))
  }
  else{
    # if only F statistic is reported - no cases of this yet!
    if (dat$Variation.Type[i] == "F_X") {
      dat$d[i] <-
        sqrt(dat$F_X[i] * (dat$N_X[i] + dat$N_C[i]) / (dat$N_C[i] * dat$N_X[i]))
      dat$var.d[i] <-
        (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
        (2 * (dat$N_C[i] + dat$N_X[i]))
      
    } else{
      # if Z and N are reported for a regression analysis
      if (dat$Variation.Type[i] == "Z_reg") {
        r <- dat$Z_X[i] / sqrt(dat$Z_N[i])
        dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
        Vr <- (1 - r ^ 2) ^ 2 / (dat$Z_N[i] - 1)
        dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
      }
      else{
        # if t and N are reported for a regression analysis
        if (dat$Variation.Type[i] == "t") {
          r <- sqrt((dat$Z_X[i] ^ 2) / (dat$Z_X[i] ^ 2 + dat$Z_df[i]))
          dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
          Vr <- (1 - r ^ 2) ^ 2 / (dat$R_N[i] - 1)
          dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
        }
        else{
          # If Z is reported from a comparison of two independent groups
          if (dat$Variation.Type[i] == "Z") {
            dat$d[i] <-
              sqrt(abs(dat$Z_X[i]) * sqrt(dat$N_C[i] + dat$N_X[i]) / (1 - sqrt(
                dat$Z_X[i] ^ 2 * (dat$N_C[i] + dat$N_X[i]) ^ -1
              )))
            dat$var.d[i] <-
              (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
              (2 * (dat$N_C[i] + dat$N_X[i]))
          }
          else{
            # converting log OR
            if (is.na(dat$Log.OR.v[i]) == FALSE &
                dat$Log.OR.v[i] > 0) {
              dat$d[i] <- dat$Log.OR[i] * (sqrt(3) / pi)
              dat$var.d[i] <- dat$Log.OR.v[i] * 3 / pi ^ 2
            } else {
              # for now, leave other types of effects as NA
              dat$d[i] <- NA
              dat$var.d[i] <- NA
            }
          }
        }
      }
    }
  }
}
```


## Correct for sample size and get g
```{r calculate g}
# sample size correction factor
for (i in 1:N) {
  # if odds ratio or comparison between means
  if (is.na(dat$N_C[i]) == F) {
    dat$J[i] <- 1 - 3 / (4 * (dat$N_C[i] + dat$N_X[i] - 2) - 1)
  } else {
    # if correlation
    if (is.na(dat$R_N[i]) == F) {
      dat$J[i] <- 1 - 3 / (4 * (dat$R_N[i] - 2) - 1)
    }else {
      dat$J[i] <- NA
    }
  }
}
# corrected effect size
dat$g <- dat$J * dat$d

# and variance
dat$var.g <- (dat$J ^ 2) * dat$var.d
```

## flip effect sizes for remaining mortality effects
```{r standardize-survival}
mort <- grep(pattern = "[M,m]ort", x = dat$Trait)

for(i in mort){
  dat$g[i] <- -dat$g[i]
}
```

# Prepare data
Filter experiments with both epidemiological and infected demographic effects
```{r divide-datasets}
# For now, get rid of NAs
dat <- dat[(is.na(dat$d) == F),]

# How many experiments do we have?
Exps <- unique(dat$Experiment)

# A data frame of experiments that included Infected demographic and Uninfected demographic effects
dat_1 <- data.frame()

# A data frame of experiments that included Infected demographic and Epidemiological effects
dat_3 <- data.frame()

# populate data sets with corresponding experiments
for (i in Exps) {
  tmp <- dat[which(dat$Experiment == i), ]
  if ("Uninfected demographic" %in% tmp$Trait.category &
      "Infected demographic" %in% tmp$Trait.category) {
    dat_1 <- rbind(dat_1, tmp)
  }
  if ("Epidemiological" %in% tmp$Trait.category &
      "Infected demographic" %in% tmp$Trait.category) {
    dat_3 <- rbind(dat_3, tmp)
  }
}

dat_1 <- dat_1[which(dat_1$Trait.category == "Uninfected demographic" | dat_1$Trait.category == "Infected demographic"),]

dat_3 <- dat_3[which(dat_3$Trait.category == "Epidemiological" | dat_3$Trait.category == "Infected demographic"),]

# A data frame with experiments that include just epidemiological effects
dat_2 <- dat_3[which(dat_3$Trait.category == "Epidemiological"),]
```

## Variance-covariance of sampling errors matrix (for multiple comparisons)
This code produces a variance-covariance of sampling errors matrix, n x n, with n = number of effect sizes. It requires the dataset (dat), Hedge's g (g), and the variance of Hedge's g (var.g) to be defined above. It uses "Experiment", "Level_C", "Trait", "N_C", and "N_X" columns.


### Identify negative eigenvalues
First, we find out which studies have negative eigenvalues in their variance-covar matrix. This means covariance between treatment effects with the same control is larger than variance and it's an indicator of suspiciously low variance and potentially an incorrectly reported N or an error while digitizing data.

For data set 1
```{r check-var-covar_1}
studies_1 <- unique(dat_1$Study)
studies_to_check <- c()
negative_eigen <- c()

for (k in studies_1) {
  dat_study <- dat_1[which(dat_1$Study == k),]
  varcovmat = matrix(0,
                     nrow = dim(dat_study)[1],
                     ncol = dim(dat_study)[1])
  
  for (i in 1:dim(dat_study)[1]) {
    for (j in 1:dim(dat_study)[1]) {
      if (i == j) {
        varcovmat[i, j] = dat_study$var.g[i]
      } else{
        if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
            dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
            dat_study[i, "Trait"] == dat_study[j, "Trait"] &
            dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
          varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
            (dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
        }
      }
    }
  }
  
  val <- eigen(varcovmat)
  for (m in 1:length(val$values)) {
    if (val$values[m] < 0) {
    studies_to_check <- append(studies_to_check, k)
    negative_eigen <- append(negative_eigen, val$values[m])
    }
  }
}
    
Neg_eigen_1 <- data.frame(study = studies_to_check, eigen = negative_eigen)

Neg_eigen_1 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```
For data set 2
```{r check-var-covar_2}
studies_2 <- unique(dat_2$Study)
studies_to_check <- c()
negative_eigen <- c()

for (k in studies_2) {
  dat_study <- dat_2[which(dat_2$Study == k),]
  varcovmat = matrix(0,
                     nrow = dim(dat_study)[1],
                     ncol = dim(dat_study)[1])
  
  for (i in 1:dim(dat_study)[1]) {
    for (j in 1:dim(dat_study)[1]) {
      if (i == j) {
        varcovmat[i, j] = dat_study$var.g[i]
      } else{
        if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
            dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
            dat_study[i, "Trait"] == dat_study[j, "Trait"] &
            dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
          varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
            (dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
        }
      }
    }
  }
  
  val <- eigen(varcovmat)
  for (m in 1:length(val$values)) {
    if (val$values[m] < 0) {
    studies_to_check <- append(studies_to_check, k)
    negative_eigen <- append(negative_eigen, val$values[m])
    }
  }
}
    
Neg_eigen_2 <- data.frame(study = studies_to_check, eigen = negative_eigen)

Neg_eigen_2 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

For data set 3
```{r check-var-covar_3}
studies_3 <- unique(dat_3$Study)
studies_to_check <- c()
negative_eigen <- c()

for (k in studies_3) {
  dat_study <- dat_3[which(dat_3$Study == k),]
  varcovmat = matrix(0,
                     nrow = dim(dat_study)[1],
                     ncol = dim(dat_study)[1])
  
  for (i in 1:dim(dat_study)[1]) {
    for (j in 1:dim(dat_study)[1]) {
      if (i == j) {
        varcovmat[i, j] = dat_study$var.g[i]
      } else{
        if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
            dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
            dat_study[i, "Trait"] == dat_study[j, "Trait"] &
            dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
          varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
            (dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
        }
      }
    }
  }
  
  val <- eigen(varcovmat)
  for (m in 1:length(val$values)) {
    if (val$values[m] < 0) {
    studies_to_check <- append(studies_to_check, k)
    negative_eigen <- append(negative_eigen, val$values[m])
    }
  }
}
    
Neg_eigen_3 <- data.frame(study = studies_to_check, eigen = negative_eigen)

Neg_eigen_3 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

Based on these eigenvalues, we looked back at the studies/experiments and determined if they had issues with reporting N or variance. We decided to remove two such studies for data set 1 (Ashraf et al. 2017 and Shostak et al. 2015) and one such study for data set 2 & 3 (Ashraf et al. 2017). 

As we found no errors or causes of concern for other studies with barely negative eigenvalues, we are forcing the var-covar matrices to the nearest positive definite values, while keeping the diagonals (var) to the estimated values and modifying only the expected covariances.

Also for now we are excluding Experiment 121 from Civitello et al 2020 Proc. B. This study has a relatively low variance for the control of the uninfected demographic fecundity effects, which results in a negative eigenvalue.

```{r var-covar-matrix}
# exclude suspicious studies with highly negative eigenvalues
dat_1 <- dat_1[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_1$Study),]
dat_1 <- dat_1[-grep("Shostak et al. 2015. Journal of Parasitology", dat_1$Study),]
dat_1 <- dat_1[-grep(121, dat_1$Experiment),]

varcovmat_1 = matrix(0, nrow = dim(dat_1)[1], ncol = dim(dat_1)[1])

for (i in 1:dim(dat_1)[1]) {
  for (j in 1:dim(dat_1)[1]) {
    if (i == j) {varcovmat_1[i,j] = dat_1$var.g[i]}else{
      if (dat_1[i, "Experiment"] == dat_1[j, "Experiment"] & dat_1[i, "Level_C"] == dat_1[j, "Level_C"] & dat_1[i, "Trait"] == dat_1[j, "Trait"] & dat_1[i, "Trait.category"] == dat_1[j, "Trait.category"]) {
        varcovmat_1[i,j] = 1/dat_1[i,"N_C"] + dat_1$g[i]*dat_1$g[j]/(dat_1[i,"N_C"] + dat_1[i,"N_X"] + dat_1[j,"N_X"]) 
      }
    }
  }
}

# correct negative eigens in the few studies with large covar to var ratios
varcovmat_1_PD <- nearPD(varcovmat_1,  keepDiag = TRUE)

# exclude suspicious studies with highly negative eigenvalues
dat_2 <- dat_2[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_2$Study),]

varcovmat_2 = matrix(0, nrow = dim(dat_2)[1], ncol = dim(dat_2)[1])

for (i in 1:dim(dat_2)[1]) {
  for (j in 1:dim(dat_2)[1]) {
    if (i == j) {varcovmat_2[i,j] = dat_2$var.g[i]}else{
      if (dat_2[i, "Experiment"] == dat_2[j, "Experiment"] & dat_2[i, "Level_C"] == dat_2[j, "Level_C"] & dat_2[i, "Trait"] == dat_2[j, "Trait"] & dat_2[i, "Trait.category"] == dat_2[j, "Trait.category"]) {
        varcovmat_2[i,j] = 1/dat_2[i,"N_C"] + dat_2$g[i]*dat_2$g[j]/(dat_2[i,"N_C"] + dat_2[i,"N_X"] + dat_2[j,"N_X"]) 
      }
    }
  }
}

# correct negative eigens in the few studies with large covar to var ratios
varcovmat_2_PD <- nearPD(varcovmat_2,  keepDiag = TRUE)

# exclude suspicious studies with highly negative eigenvalues
dat_3 <- dat_3[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_3$Study),]

# Carrington et al. 2013 has extremely large sampling variance for a parasite prevalence effect. DOUBLE CHECK!!!
dat_3 <- dat_3[-grep("Carrington et al. 2013. PLOS NegTropDiseases", dat_3$Study),]

varcovmat_3 = matrix(0, nrow = dim(dat_3)[1], ncol = dim(dat_3)[1])

for (i in 1:dim(dat_3)[1]) {
  for (j in 1:dim(dat_3)[1]) {
    if (i == j) {varcovmat_3[i,j] = dat_3$var.g[i]}else{
      if (dat_3[i, "Experiment"] == dat_3[j, "Experiment"] & dat_3[i, "Level_C"] == dat_3[j, "Level_C"] & dat_3[i, "Trait"] == dat_3[j, "Trait"] & dat_3[i, "Trait.category"] == dat_3[j, "Trait.category"]) {
        varcovmat_3[i,j] = 1/dat_3[i,"N_C"] + dat_3$g[i]*dat_3$g[j]/(dat_3[i,"N_C"] + dat_3[i,"N_X"] + dat_3[j,"N_X"]) 
      }
    }
  }
}  

# correct eigenvalues in the few studies with large covar to var ratios
varcovmat_3_PD <- nearPD(varcovmat_3, keepDiag = TRUE)

# For now remove rare host types to check interaction with host
dat_3_byHost <- dat_3[which(dat_3$Host.type == "Arthropod" | dat_3$Host.type == "Mollusc" | dat_3$Host.type == "Fish" | dat_3$Host.type == "Amphibian"), ]

varcovmat_3_byHost = matrix(0, nrow = dim(dat_3_byHost)[1], ncol = dim(dat_3_byHost)[1])

for (i in 1:dim(dat_3_byHost)[1]) {
  for (j in 1:dim(dat_3_byHost)[1]) {
    if (i == j) {varcovmat_3_byHost[i,j] = dat_3_byHost$var.g[i]}else{
      if (dat_3_byHost[i, "Experiment"] == dat_3_byHost[j, "Experiment"] & dat_3_byHost[i, "Level_C"] == dat_3_byHost[j, "Level_C"] & dat_3_byHost[i, "Trait"] == dat_3_byHost[j, "Trait"] & dat_3_byHost[i, "Trait.category"] == dat_3_byHost[j, "Trait.category"]) {
        varcovmat_3_byHost[i,j] = 1/dat_3_byHost[i,"N_C"] + dat_3_byHost$g[i]*dat_3_byHost$g[j]/(dat_3_byHost[i,"N_C"] + dat_3_byHost[i,"N_X"] + dat_3_byHost[j,"N_X"]) 
      }
    }
  }
}

# correct eigenvalues in the few studies with large covar to var ratios
varcovmat_3_byHost_PD <- nearPD(varcovmat_3_byHost,  keepDiag = TRUE)
```

Create a new column with a category of vertebrate or invertebrate
```{r vertebrate/invertebrate host category, echo=FALSE}
dat_1 <- mutate(dat_1, Host.type.2 = case_when(
  Host.type == "Fish" ~ "Vertebrate",
  Host.type == "Arthropod" ~ "Invertebrate",
  Host.type == "Amphibian" ~ "Vertebrate",
  Host.type == "Mollusc" ~ "Invertebrate"))

dat_2 <- mutate(dat_2, Host.type.2 = case_when(
  Host.type == "Fish" ~ "Vertebrate",
  Host.type == "Arthropod" ~ "Invertebrate",
  Host.type == "Amphibian" ~ "Vertebrate",
  Host.type == "Mollusc" ~ "Invertebrate",
  Host.type == "Reptile" ~ "Vertebrate",
  Host.type == "Bird" ~ "Vertebrate",
  Host.type == "Mammal" ~ "Vertebrate"))

dat_3 <- mutate(dat_3, Host.type.2 = case_when( 
  Host.type == "Fish" ~ "Vertebrate",
  Host.type == "Arthropod" ~ "Invertebrate",
  Host.type == "Amphibian" ~ "Vertebrate",
  Host.type == "Mollusc" ~ "Invertebrate",
  Host.type == "Reptile" ~ "Vertebrate",
  Host.type == "Bird" ~ "Vertebrate",
  Host.type == "Mammal" ~ "Vertebrate"))

```


# Descriptive statistics
```{r descriptive-stats, echo=FALSE}
d_stats <-
  data.frame(
    stat = c(
      "Number of papers",
      "Number of effects",
      "Number of experiments",
      "Number of arthropod species",
      "Number of mollusc species",
      "Number of fish species",
      "Number of amphibian species",
      "Number of reptile species",
      "Number of bird species",
      "Number of mammal species",
      "Number of viral taxa",
      "Number of bacterial taxa",
      "Number of Multiple infection",
      "Number of fungal taxa",
      "Number of protozan taxa",
      "Number of helminth taxa",
      "Number of environment experiments",
      "Number of pollution experiments",
      "Number of resource experiments",
      "Number of resistance effects",
      "Number of prevalence effects",
      "Number of intensity effects",
      "Number of fitness effects",
      "Number of survival effects",
      "Number of fecundity effects"
    ),
    Question_1 = c(
      length(unique(dat_1$Study)),
      length(dat_1$g),
      length(unique(dat_1$Experiment)),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Arthropod")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Mollusc")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Fish")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Amphibian")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Reptile")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Bird")])),
      length(unique(dat_1$Host[which(dat_1$Host.type == "Mammal")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Virus")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Bacteria")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Multiple")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Fungus")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Protozoan")])),
      length(unique(dat_1$Parasite[which(dat_1$Parasite.type ==
                                           "Helminth")])),
      length(dat_1$Experiment[which(dat_1$Gradient.category ==
                                      "Environment")]),
      length(dat_1$Experiment[which(dat_1$Gradient.category ==
                                      "Pollution")]),
      length(dat_1$Experiment[which(dat_1$Gradient.category ==
                                      "Resource")]),
      length(dat_1$ID[which(dat_1$Trait.category == "Epidemiological")]),
      length(dat_1$ID[which(dat_1$Trait.type == "Prevalence")]),
      length(dat_1$ID[which(dat_1$Trait.type == "Intensity")]),
      length(dat_1$ID[grep("demographic", dat_1$Trait.category)]),
      length(dat_1$ID[which(dat_1$Trait.type == "Survivorship")]),
      length(dat_1$ID[which(dat_1$Trait.type == "Fecundity")])
    ),
    Question_2 = c(
      length(unique(dat_2$Study)),
      length(dat_2$g),
      length(unique(dat_2$Experiment)),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Arthropod")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Mollusc")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Fish")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Amphibian")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Reptile")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Bird")])),
      length(unique(dat_2$Host[which(dat_2$Host.type == "Mammal")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Virus")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Bacteria")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Multiple")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Fungus")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Protozoan")])),
      length(unique(dat_2$Parasite[which(dat_2$Parasite.type ==
                                           "Helminth")])),
      length(dat_2$Experiment[which(dat_2$Gradient.category ==
                                      "Environment")]),
      length(dat_2$Experiment[which(dat_2$Gradient.category ==
                                      "Pollution")]),
      length(dat_2$Experiment[which(dat_2$Gradient.category ==
                                      "Resource")]),
      length(dat_2$ID[which(dat_2$Trait.category == "Epidemiological")]),
      length(dat_2$ID[which(dat_2$Trait.type == "Prevalence")]),
      length(dat_2$ID[which(dat_2$Trait.type == "Intensity")]),
      length(dat_2$ID[grep("demographic", dat_2$Trait.category)]),
      length(dat_2$ID[which(dat_2$Trait.type == "Survivorship")]),
      length(dat_2$ID[which(dat_2$Trait.type == "Fecundity")])
    ),
    Question_3 = c(
      length(unique(dat_3$Study)),
      length(dat_3$g),
      length(unique(dat_3$Experiment)),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Arthropod")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Mollusc")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Fish")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Amphibian")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Reptile")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Bird")])),
      length(unique(dat_3$Host[which(dat_3$Host.type == "Mammal")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Virus")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Bacteria")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Multiple")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Fungus")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Protozoan")])),
      length(unique(dat_3$Parasite[which(dat_3$Parasite.type ==
                                           "Helminth")])),
      length(dat_3$Experiment[which(dat_3$Gradient.category ==
                                      "Environment")]),
      length(dat_3$Experiment[which(dat_3$Gradient.category ==
                                      "Pollution")]),
      length(dat_3$Experiment[which(dat_3$Gradient.category ==
                                      "Resource")]),
      length(dat_3$ID[which(dat_3$Trait.category == "Epidemiological")]),
      length(dat_3$ID[which(dat_3$Trait.type == "Prevalence")]),
      length(dat_3$ID[which(dat_3$Trait.type == "Intensity")]),
      length(dat_3$ID[grep("demographic", dat_3$Trait.category)]),
      length(dat_3$ID[which(dat_3$Trait.type == "Survivorship")]),
      length(dat_3$ID[which(dat_3$Trait.type == "Fecundity")])
    )
  )

d_stats %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```


# Preliminary analysis

## Question 1 - Are fitness traits negatively affected by stressors
### Null model
```{r Q1-null}
Q1m1 <-
  rma.mv(
    g ~ 1,
    V = varcovmat_1_PD$mat,
    random = list(  ~ 1 |Experiment/ID, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m1)
```


### Effects in uninfected vs infected hosts, do they differe between survival vs fecundity?
```{r Q1-single-fixed}
Q1m2 <-
  rma.mv(
    g ~ Trait.category:Trait.type -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | as.factor(ID), ~ 1 | as.factor(Experiment), ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m2)
forest.default(x= Q1m2$beta, sei =  Q1m2$se, ci.lb =  Q1m2$ci.lb, ci.ub =  Q1m2$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Infected fecundity", "Uninfected fecundity", 
                          "Infected survivorship", "Uninfected survivorship"))
```

### Effects in uninfected vs infected hosts, do they differe between survival vs fecundity, once we account for type of stress
```{r Q1-single-fixed}
Q1m3 <-
  rma.mv(
    g ~ Trait.category : Trait.type : Gradient.category -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m3)
forest.default(x= Q1m3$beta, sei =  Q1m3$se, ci.lb =  Q1m3$ci.lb, ci.ub =  Q1m3$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment infected fecundity", "Environment uninfected fecundity", "Environment infected survivorship", "Environment uninfected survivorship", "Pollution infected fecundity", "Pollution uninfected fecundity", "Pollution infected survivorship", "Pollution uninfected survivorship", "Resource infected fecundity", "Resource uninfected fecundity", "Resource infected survivorship", "Resource uninfected survivorship"))
```

### Effects in  survival vs fecundity measures of fitness under different types of stress, combining infected and uninfected
```{r Q1-single-fixed}
Q1m4 <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1 ,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m4)
forest.default(x= Q1m4$beta, sei =  Q1m4$se, ci.lb =  Q1m4$ci.lb, ci.ub =  Q1m4$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment fecundity", "Environment survivorship", "Pollution  fecundity", "Pollution  survivorship", "Resource  fecundity", "Resource  survivorship"))
```

### Trait category x Host type interaction
```{r Q1-Trait-x-Host}
Q1m5 <-
  rma.mv(
    g ~ Trait.category:Host.type.2 -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m5)
forest.default(x= Q1m5$beta, sei =  Q1m5$se, ci.lb =  Q1m5$ci.lb, ci.ub =  Q1m5$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Invertebrate infected", "Invertebrate uninfected", "Vertebrate infected", "Vertebrate  uninfected"))
```

### Trait category x Stress type x Host type interaction
```{r Q1-Trait-x-Host}
Q1m6 <-
  rma.mv(
    g ~ Trait.category:Gradient.category:Host.type.2 -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m6)
forest.default(x= Q1m6$beta, sei =  Q1m6$se, ci.lb =  Q1m6$ci.lb, ci.ub =  Q1m6$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate infected", "Environment invertebrate uninfected", "Pollution invertebrate infected", "Pollution invertebrate uninfected", "Resource invertebrate infected", "Resource invertebrate uninfected", "Environment vertebrate infected", "Environment vertebrate uninfected", "Pollution vertebrate infected", "Pollution vertebrate uninfected", "Resource vertebrate infected", "Resource vertebrate uninfected"))
```

### Trait type x Stress type x Host type interaction
This model should not be included in the model selection, because it is missing categories (we don't have data of fecundity from vertebrates)
```{r Q1-Trait-x-Host}
Q1m7 <-
  rma.mv(
    g ~ Trait.type:Gradient.category:Host.type.2 -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m7)
forest.default(x= Q1m7$beta, sei =  Q1m7$se, ci.lb =  Q1m7$ci.lb, ci.ub =  Q1m7$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate fecundity", "Environment invertebrate survivorship", "Pollution invertebrate fecundity", "Pollution invertebrate survivorship", "Resource invertebrate fecundity", "Resource invertebrate survivorship", "Environment vertebrate survivorship", "Pollution vertebrate survivorship", "Resource vertebrate survivorship"))
```

### Stress type x Host type interaction, combining infected and uninfected
```{r Q1-Trait-x-Host}
Q1m8 <-
  rma.mv(
    g ~ Gradient.category:Host.type.2 -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_1,
    method = "REML"
  )

summary(Q1m8)
forest.default(x= Q1m8$beta, sei =  Q1m8$se, ci.lb =  Q1m8$ci.lb, ci.ub =  Q1m8$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate", "Pollution invertebrate", "Resource invertebrate", "Environment vertebrate", "Pollution vertebrate", "Resource vertebrate "))
```

### Model selection
#### Using MuMIn package
```{r}
# First, we evaluate some code that generates helper functions needed so that metafor and MuMIn could interact as necessary
eval(metafor:::.MuMIn)

# Now, we take the full model and fit the rest of the models and examine those models whose AICc value is no more than 10 units away from that of the best model
full_model.1 <- rma.mv(
    g,
    V = varcovmat_1_PD$mat,
    mods = ~ Trait.category*Trait.type*Gradient.category, 
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_1,
    method = "ML"
  )

model_selection.1 <- dredge(full_model.1, trace = 2) 
subset(model_selection.1, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method

# Multimodel inference
average.model.1 <- model.avg(model_selection.1, revised.var=FALSE)
summary(average.model.1) #Set revised.var = F to get same results as we would with the glmulti package

# relative importance values for the predictors can be obtained with:
importance(model_selection.1)

# Best model Q1m4
```

## Question 2 - Are resistance traits negatively affected by stressors
### Null model
```{r Q2-null}
Q2m1 <-
  rma.mv(
    g ~ 1,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | as.factor(ID), ~ 1 | as.factor(Experiment), ~ 1 | Parasite),
    data = dat_2,
    method = "REML"
  )

summary(Q2m1)
```

### Does resistance decrease with stress, does it differe between prevalence vs intensity?
```{r Q2-single-fixed}
Q2m2 <-
  rma.mv(
    g ~ Trait.type -1 ,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | as.factor(ID), ~ 1 | as.factor(Experiment), ~ 1 | Parasite),
    data = dat_2,
    method = "REML"
  )

summary(Q2m2)
forest.default(x= Q2m2$beta, sei =  Q2m2$se, ci.lb =  Q2m2$ci.lb, ci.ub =  Q2m2$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Intensity", "Prevalence"))
```

### Do they differe between prevalence vs intensity, once we account for type of stress
```{r Q2-single-fixed}
Q2m3 <-
  rma.mv(
    g ~ Trait.type : Gradient.category -1,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 |Experiment/ID, ~ 1 | Parasite),
    data = dat_2,
    method = "REML"
  )

summary(Q2m3)
forest.default(x= Q2m3$beta, sei =  Q2m3$se, ci.lb =  Q2m3$ci.lb, ci.ub =  Q2m3$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment intensity", "Environment prevalence", "Pollution intensity", "Pollution prevalence", "Resource intensity", "Resource prevalence"))
```


### Trait type x Host type interaction
```{r Q2-Trait-x-Host}
Q2m4 <-
  rma.mv(
    g ~ Trait.type:Host.type.2:Gradient.category -1,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_2,
    method = "REML"
  )

summary(Q2m4)
forest.default(x= Q2m4$beta, sei =  Q2m4$se, ci.lb =  Q2m4$ci.lb, ci.ub =  Q2m4$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate intensity", "Environment invertebrate prevalence", "Environment vertebrate intensity", "Environment vertebrate prevalence", "Pollution invertebrate intensity", "Pollution invertebrate prevalence", "Pollution vertebrate intensity", "Pollution vertebrate prevalence", "Resource invertebrate intensity", "Resource invertebrate prevalence", "Resource vertebrate intensity", "Resource vertebrate prevalence"))
```
### Does the response depends on stress type 
```{r Q2-Stress-Type}
Q2m5 <-
  rma.mv(
    g ~ Gradient.category -1,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_2,
    method = "REML"
  )

summary(Q2m5)
forest.default(x= Q2m5$beta, sei =  Q2m5$se, ci.lb =  Q2m5$ci.lb, ci.ub =  Q2m5$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment", "Pollution", "Resource"))
```
### Model selection
This section is a work in progress...

#### Using glmulti package
```{r}
# Define a function that takes a model formula and a dataset as input and then fits a random/mixed-effects meta-regression model to the given data using maximum likelihood estimation (to compare models we have to use ML, and then we can re-fit with REML)
rma.glmulti <- function(formula, data, V, random, ...){
   rma.mv(formula, V = V, data = data, random = random, method="ML", ...) 
}

# Fit all models
all.models.2 <- glmulti(g ~ Trait.type*Gradient.category, 
               data=dat_2,
               V = varcovmat_2_PD$mat, 
               random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
               level = 2, fitfunction = rma.glmulti, crit="aicc", marginality = TRUE)

# --> Tried "intercept = F", to exclude the intercept from  the candidate models, and got "Error in x[, ii] : subscript out of bounds"

# summary
print(all.models.2)

# plot of AICc values for the models. The line separates the models that are less or more that 2 units away from the best model
plot(all.models.2)

# Top models
top.models.2 <- weightable(all.models.2)
top.models.2 <- top.models.2[top.models.2$aicc <= min(top.models.2$aicc) + 2,]
top.models.2

# Variable importance plot across all the models
plot(all.models.2, type="s")
# --> none of them reach >= 0.8

#Multimodel inference - make inferences about various predictors across all possible models relative to their weights

#To get the glmulti package to handle rma.uni objects, we must register a getfit method for such objects
eval(metafor:::.glmulti)

coef(all.models.2)

# Organized table, getting the unconditional estimates
mmi.2 <- as.data.frame(coef(all.models.2))
mmi.2 <- data.frame(Estimate=mmi.2$Est, SE=sqrt(mmi.2$Uncond), Importance=mmi.2$Importance, row.names=row.names(mmi.2))
mmi.2$z <- mmi.2$Estimate / mmi.2$SE
mmi.2$p <- 2*pnorm(abs(mmi.2$z), lower.tail=FALSE)
names(mmi.2) <- c("Estimate", "Std. Error", "Importance", "z value", "Pr(>|z|)")
mmi.2$ci.lb <- mmi.2[[1]] - qnorm(.975) * mmi.2[[2]]
mmi.2$ci.ub <- mmi.2[[1]] + qnorm(.975) * mmi.2[[2]]
mmi.2 <- mmi.2[order(mmi.2$Importance, decreasing=TRUE), c(1,2,4:7,3)]
round(mmi.2, 4)

#Multimodel predictions
# --> Note: how (and when) can we re-fit the model with REML?
#           how do we deal with interactions?

# x <- data.frame("Gradient.category" = c("Environment", "Pollution", "Resource", "Environment", "Pollution", "Resource"), "Trait.type" = c("Intensity", "Intensity", "Intensity", "Prevalence", "Prevalence", "Prevalence"))
# predict.glmulti(res, varweighting = "Buckland", newdata = x, icmethod = "Lukacs", se.fit = TRUE)

preds <- list()

x <- c("Gradient.categoryPollution" = T, "Gradient.categoryResource" = F, "Trait.typePrevalence" = T, "Gradient.categoryEnvironment:Trait.typeIntensity" = F, "Gradient.categoryPollution:Trait.typeIntensity" = F, 
"Gradient.categoryResource:Trait.typeIntensity" = F, "Gradient.categoryEnvironment:Trait.typePrevalence" = F,
"Gradient.categoryPollution:Trait.typePrevalence" = F, 
"Gradient.categoryResource:Trait.typePrevalence" = F,
"Trait.typePrevalence:Gradient.categoryResource" = F, 
"Trait.typePrevalence:Gradient.categoryPollution" = F,
"Trait.typePrevalence:Gradient.categoryEnvironment" = F,
"Trait.typeIntensity:Gradient.categoryResource" = F,
"Trait.typeIntensity:Gradient.categoryPollution" = F,
"Trait.typeIntensity:Gradient.categoryEnvironment" = F)

#Missing Gradient.categoryEnvironment and Trait.typeIntensity
 
for (j in 1:all.models.2@nbmods) {
   model <- all.models.2@objects[[j]]
   vars <- names(coef(model))[-1]
   if (length(vars) == 0) {
      preds[[j]] <- predict(model)
   } else {
      preds[[j]] <- predict(model, newmods=x[vars])
   }
}

weights <- weightable(all.models.2)$weights
yhat <- sum(weights * sapply(preds, function(x) x$pred))
round(yhat, 3)
se <- sqrt(sum(weights * sapply(preds, function(x) x$se^2 + (x$pred - yhat)^2)))
round(yhat + c(-1,1)*qnorm(.975)*se, 3)

```

#### Using MuMIn package
```{r}
# Now, we take the full model and fit the rest of the models and examine those models whose AICc value is no more than 10 units away from that of the best model
full_model.2 <- rma.mv(
    g,
    V = varcovmat_2_PD$mat,
    mods = ~ Trait.type * Gradient.category, 
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_2,
    method = "ML"
  )

model_selection.2 <- dredge(full_model.2, trace = 2) 
subset(model_selection.2, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method

# Multimodel inference
average.model.2 <- model.avg(model_selection.2, revised.var=FALSE)
summary(average.model.2) #Set revised.var = F to get same results as we would with the glmulti package

# relative importance values for the predictors can be obtained with:
importance(model_selection.2)

#How do we get model predictions? - Still not working
predict(average.model.2, se.fit = T)
predict(average.model.2, newdata = data.frame(c("Gradient.categoryPollution" = T, "Gradient.categoryResource" = F, "Trait.typePrevalence" = T, "Gradient.categoryPollution:Trait.typePrevalence" = F, 
"Gradient.categoryResource:Trait.typePrevalence" = F)), se.fit = T)
```


## Question 3 - Do resistance and fitness traits have different sensitivity to stressors
### Null model
```{r Q3-null}
Q3m1 <-
  rma.mv(
    g ~ 1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML"
  )

summary(Q3m1)

```

### Single fixed effect
```{r Q3-single-fixed}
#note that this is WITH absolute value --> which one is more sensible. Both are significant.
Q3m2.1 <-
  rma.mv(
   abs(g) ~ Trait.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML"
  )

summary(Q3m2.1)
forest.default(x= Q3m2.1$beta, sei =  Q3m2.1$se, ci.lb =  Q3m2.1$ci.lb, ci.ub =  Q3m2.1$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("epidemiological", "Fitness"))
```
```{r Q3-single-fixed}
#note that this is WITHOUT absolute value --> In here, resistance is not significant. Which means that the responses to stress are all over the place, while for the fitness trait is always a negative effect. Could be explained by dying individuals when getting infected, which might look like an increase in resistance (??)

Q3m2.2 <-
  rma.mv(
   g ~ Trait.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML"
  )

summary(Q3m2.2)
forest.default(x= Q3m2.2$beta, sei =  Q3m2.2$se, ci.lb =  Q3m2.2$ci.lb, ci.ub =  Q3m2.2$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Epidemiological", "Fitness"))
```


### Trait category x Gradient category interaction
```{r Q3-Trait-x-Gradient}
Q3m3 <-
  rma.mv(
    g ~ Trait.category:Gradient.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML"
  )

summary(Q3m3)
forest.default(x= Q3m3$beta, sei =  Q3m3$se, ci.lb =  Q3m3$ci.lb, ci.ub =  Q3m3$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment epidemiological", "Environment fitness", "Pollution epidemiological", "Pollution fitness", "Resource epidemiological", "Resource fitness"))
```

### Trait type x Gradient category interaction
```{r Q3-Trait-x-Gradient}
Q3m4 <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_3,
    method = "REML",
)

summary(Q3m4)
forest.default(x= Q3m4$beta, sei =  Q3m4$se, ci.lb =  Q3m4$ci.lb, ci.ub =  Q3m4$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment fecundity", "Environment intensity", "Environment prevalence", "Environment survivorship", "Pollution fecundity", "Pollution intensity", "Pollution prevalence", "Pollution survivorship", "Resource fecundity", "Resource intensity", "Resource prevalence", "Resource survivorship"))
```
### Trait category x Host type interaction
```{r Q3-Trait-x-Host}
Q3m5 <-
  rma.mv(
    g ~ Trait.category:Host.type.2 -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML",
)

summary(Q3m5)
forest.default(x= Q3m5$beta, sei =  Q3m5$se, ci.lb =  Q3m5$ci.lb, ci.ub =  Q3m5$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Resistance invertebrate", "Fitness invertebrate", "Resistance vertebrate", "Fitness vertebrate"))
```
### Trait category x Invert/Vert x Stressor type
```{r Q3-Trait-x-Host}
Q3m6 <-
  rma.mv(
    g ~ Trait.category:Host.type.2:Gradient.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML",
)

summary(Q3m6)
forest.default(x= Q3m6$beta, sei =  Q3m6$se, ci.lb =  Q3m6$ci.lb, ci.ub =  Q3m6$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate epidemiological", "Environment invertebrate fitness", "Environment vertebrate epidemiological", "Environment vertebrate fitness", "Pollution invertebrate epidemiological", "Pollution invertebrate fitness", "Pollution vertebrate epidemiological", "Pollution vertebrate fitness", "Resource invertebrate epidemiological", "Resource invertebrate fitness", "Resource vertebrate epidemiological", "Resource vertebrate fitness"))

```
### Trait type x Invert/Vert x stressor type
```{r Q3-Trait-x-Host}
Q3m7 <-
  rma.mv(
    g ~ Trait.type:Host.type.2:Gradient.category -1,
    V = varcovmat_3_PD$mat,
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "REML",
)

summary(Q3m7)
forest.default(x= Q3m7$beta, sei =  Q3m7$se, ci.lb =  Q3m7$ci.lb, ci.ub =  Q3m7$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment invertebrate fecundity", "Environment invertebrate intensity", "Environment invertebrate prevalence", "Environment invertebrate survivorship", "Environment vertebrate intensity", "Environment vertebrate prevalence", "Environment vertebrate survivorship", "Pollution invertebrate fecundity", "Pollution invertebrate intensity", "Pollution invertebrate prevalence", "Pollution invertebrate survivorship", "Pollution vertebrate intensity", "Pollution vertebrate prevalence", "Pollution vertebrate survivorship", "Resource invertebrate fecundity", "Resource invertebrate intensity", "Resource invertebrate prevalence", "Resource invertebrate survivorship", "Resource vertebrate intensity", "Resource vertebrate prevalence", "Resource vertebrate survivorship"))

```

### Model selection
#### Using MuMIn package
```{r}
full_model.3 <- rma.mv(
    g,
    V = varcovmat_3_PD$mat,
    mods = ~ Trait.type*Gradient.category, 
    random = list( ~ 1 | ID, ~ 1 | Experiment, ~ 1 | Parasite),
    data = dat_3,
    method = "ML"
  )
# Define if using Trait.type or Trait.category
model_selection.3 <- dredge(full_model.3, trace = 2) 
subset(model_selection.3, delta <= 10, recalc.weights = FALSE)
# --> I am getting different weights (and therefore different unconditional estimates) than with the glmulti method

# Multimodel inference
average.model.3 <- model.avg(model_selection.3, revised.var=FALSE)
summary(average.model.3) #Set revised.var = F to get same results as we would with the glmulti package

# relative importance values for the predictors can be obtained with:
importance(model_selection.3)

#Best model Q3m4
```

# Publication bias

I tried to check for publication bias in our three data sets and see which correction methods would be suitable. The most common way to assess publication bias is to test whether studies with large standard errors tend to have larger effect sizes. Small studies have larger SEs, and because they are small, they are more likely to get published only if results are significant. In contrast, large studies, which have higher precision and have costed more money, are more likely to get published either way.

### Funnel plots
A very common way to assess publication bias is therefore to check whether studies with low precision have larger effects. The typical way to visualize this is through a funnel plot. Now, this is not entirely correct for us, as the effects are not independent. I don't know what is the best way to go about this, but for now I'm simply showing points from the same experiment in the same colour.

**Note** I checked some previous studies that use multilevel regression models as we do here, to see what they do about publication bias. Sauer et al 2020 Ecology (101) acknowledged this problem and decided not to even show funnel plots: "Because of the complex non independence among effect sizes within a study (e.g., some studies had multiple effect sizes), we did not use funnel plots or rank correlation tests to assess publication bias (Lau et al. 2006, Civitello et al.2015)." Others (Yates et al. 2019 Environmental DNA (1); Salerno et al 2021 Global Change Biology (27); Brlik et al. 2020 JAE) acknowledge this problem, but still show funnel plots warning caution. They also conduct a version of Eggerts test which I do below.

#### Data set 1: fitness effects of environmental stress
```{r dat_1-funnel}
# make new factor for colour grouping
nlvl <- length(unique(dat_1$Experiment))
pal <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_1$Exp_nn <- as.factor(x=dat_1$Experiment)
levels(dat_1$Exp_nn) <- as.factor(seq(1:nlvl))

# plot funnel
metafor::funnel(dat_1$g, dat_1$var.g, level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_1$Exp_nn], back = "white", refline=0, legend=TRUE)

# maybe we want to visualize the two fitness traits separately
dat_1_Surv <-dat_1[which(dat_1$Trait.type == "Survivorship"),]

# colour grouping
nlvl <- length(unique(dat_1_Surv$Experiment))
pal_Surv <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_1_Surv$Exp_nn <- as.factor(x=dat_1_Surv$Experiment)
levels(dat_1_Surv$Exp_nn) <- as.factor(seq(1:nlvl))

# plot funnel
metafor::funnel(dat_1_Surv$g, dat_1_Surv$var.g, level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_1_Surv$Exp_nn], back = "white", refline=0, legend=TRUE)

# for fecundity
dat_1_Fecund <-dat_1[which(dat_1$Trait.type == "Fecundity"),]

# colour grouping
nlvl <- length(unique(dat_1_Fecund$Experiment))
pal_Fecund <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_1_Fecund$Exp_nn <- as.factor(x=dat_1_Fecund$Experiment)
levels(dat_1_Fecund$Exp_nn) <- as.factor(seq(1:nlvl))

#plot funnel
metafor::funnel(x = dat_1_Fecund$g, vi = dat_1_Fecund$var.g,  level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_1_Fecund$Exp_nn], back = "white", refline=0, legend=TRUE)
```

We can see that as SE increases (e.g > 1) all studies report significant negative fitness effects of environmental stress. In other words, it seems that very small studies tend to find more significant effects.

#### Data set 2: resistance effects of environmental stress
```{r dat_2-funnel}
# make new factor for colour grouping
nlvl <- length(unique(dat_2$Experiment))
pal <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_2$Exp_nn <- as.factor(x=dat_2$Experiment)
levels(dat_2$Exp_nn) <- as.factor(seq(1:nlvl))

# plot funnel
metafor::funnel(dat_2$g, dat_2$var.g, level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_2$Exp_nn], back = "white", refline=0, legend=TRUE)

# there is one extreme study with low precision and apparently a huge effect size. Which one is it?
dat_2$Study[which(dat_2$var.g == max(dat_2$var.g))]

# let's see how it looks without that one
dat_2_no <- dat_2[-which(dat_2$Study == "Carrington et al. 2013. PLOS NegTropDiseases"),]

# make new factor for colour grouping
nlvl <- length(unique(dat_2_no$Experiment))
pal <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_2_no$Exp_nn <- droplevels(dat_2_no$Exp_nn)
levels(dat_2_no$Exp_nn) <- as.factor(seq(1:nlvl))

metafor::funnel(dat_2_no$g, dat_2_no$var.g, level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_2_no$Exp_nn], back = "white", refline=0, legend=TRUE)

# maybe we want to visualize the two resistance traits separately
dat_2_Int <-dat_2[which(dat_2$Trait.type == "Intensity"),]

# colour grouping
nlvl <- length(unique(dat_2_Int$Experiment))
pal_Int <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_2_Int$Exp_nn <- as.factor(x=dat_2_Int$Experiment)
levels(dat_2_Int$Exp_nn) <- as.factor(seq(1:nlvl))

# plot funnel
metafor::funnel(dat_2_Int$g, dat_2_Int$var.g, level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_2_Int$Exp_nn], back = "white", refline=0, legend=TRUE)

# for prevalence
dat_2_Pre <-dat_2_no[which(dat_2$Trait.type == "Prevalence"),]

# colour grouping
nlvl <- length(unique(dat_2_Pre$Experiment))
pal_Pre <- wes_palette("Darjeeling1", nlvl, type = "continuous")
dat_2_Pre$Exp_nn <- as.factor(x=dat_2_Pre$Experiment)
levels(dat_2_Pre$Exp_nn) <- as.factor(seq(1:nlvl))

#plot funnel
metafor::funnel(x = dat_2_Pre$g, vi = dat_2_Pre$var.g,  level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal[dat_2_Pre$Exp_nn], back = "white", refline=0, legend=TRUE)
```

### Modified Eggert's test
Eggert's test is essentially a regression between effect sizes and precision. Studies with large SE have low precision. When precision is 0, the expected effect size  should be 0. Even if there is a real effect, without precision one shouldn't find it. So we are interested in the intercept of this regression (effect size when precision is 0) and testing whether this intercept differs from 0. If it does, we can suspect there is a bias caused by small studies, which can in turn be caused by publication bias.

In this case we want to use the same multilevel approach as in our main models to accounts for the non-independence of effects coming from the same study (or conducted with the same parasite). I've seen versions of this with the effect sizes (g) or the residuals of null models (without fixed predictors). Here, I include both.

#### Data set 1: fitness effects of environmental stress

```{r dat_1-Eggert}
# get residuals from null model
dat_1$res <- rstandard.rma.mv(Q1m1)$res

# calculate precision
dat_1$precision <-  1/sqrt(dat_1$var.g)

# meta regression with effect size
rma.mv(g ~ precision,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_1,
    method = "REML")

# meta regression with residual
rma.mv(res ~ precision,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_1,
    method = "REML")
```

Both cases suggest bias, in that even infinitely small studies would find a negative effect of environmental stress on fitness.

#### Data set 2: resistance effects of environmental stress

```{r dat_2-Eggert}
# get residuals from null model
dat_2$res <- rstandard.rma.mv(Q2m1)$res

# calculate precision
dat_2$precision <-  1/sqrt(dat_2$var.g)

# meta regression with effect size
rma.mv(g ~ precision,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_2,
    method = "REML")

# meta regression with residual
rma.mv(res ~ precision,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | Experiment/ID, ~ 1 | Parasite),
    data = dat_2,
    method = "REML")
```
Even when we include Carrington et al 2013, we don't find evidence of publication bias here.

### What to do if there is bias?
The studies I saw using a version Eggert's test and find evidence of publication bias, define a precision/study size threshold, remove studies below this threshold and see if that alters their results substantially. This is not an elegant solution but might be the best we have as all methods that I could find to adjust effect sizes do not work for multilevel models (rma.mv).

### Weighting the effects of (small) studies
A related question that one could want to check is how different studies contribute to the overall effects to see. In other words is our main result being driven by a few studies? Here I compute and plot a few measures of outlier/influence diagnostics.

I'm also calculating the influence statistics cooks distance and dfbetas at the level of studies. In the metafor man pages: 

"Cook's distance can be interpreted as the Mahalanobis distance between the entire set of predicted values once with the th case included and once with the th case excluded from the model fitting." 

"the DFBETAS value(s) essentially indicate(s) how many standard deviations the estimated coefficient(s) change(s) after excluding the th case from the model fitting."

A value is influential if "The hat value is larger than 3(/)." where p is the number of coefficients and k the number of cases.

#### Data set 1: fitness effects of environmental stress
I'm running the analysis here for the model with the lowest AIC (Q1m4). We should probably do it for which ever model is our main model in the manuscript (probably this one?)

```{r dat_1-influence}
# Cook's distance
Cook_dat1 <- cooks.distance(Q1m4, progbar=TRUE, dat_1$Study, reestimate=TRUE, parallel="multicore", ncpus = 2)

# how are these distances distributes?
hist(Cook_dat1)

# Which are the most influential studies?
Cook_dat1[which(Cook_dat1 > 1)]

# dfbetas
dfbetas_dat1 <- dfbetas.rma.mv(Q1m4, progbar=TRUE, dat_1$Study, reestimate=TRUE, parallel="multicore")

# Which are the most influential studies?
dfbetas_dat1[abs(dfbetas_dat1[,1])>1 | abs(dfbetas_dat1[,2])>1
             | abs(dfbetas_dat1[,3])>1 | abs(dfbetas_dat1[,4])>1
             | abs(dfbetas_dat1[,5])>1 | abs(dfbetas_dat1[,6])>1,]

# hat values
hat_dat1 <- hatvalues(Q1m4) 

# Which are the most influential effects?
inf_cutoff <- 3 * length(Q1m4$beta)/nrow(dat_1)

dat_1$Study[hat_dat1 > inf_cutoff]
```

#### Data set 2: resistance effects of environmental stress
I'm running the analysis here for the model with the lowest AIC (Q2m4). We should probably do it for which ever model is our main model in the manuscript (probably this one?)

```{r dat_2-influence}
# Cook's distance
Cook_dat2 <- cooks.distance(Q2m4, progbar=TRUE, dat_2$Study, reestimate=TRUE, parallel="multicore", ncpus = 2)

# how are these distances distributes?
hist(Cook_dat2)

# Which are the most influential studies?
Cook_dat2[which(Cook_dat2 > 1)]

# dfbetas
dfbetas_dat2 <- dfbetas.rma.mv(Q2m4, progbar=TRUE, dat_2$Study, reestimate=TRUE, parallel="multicore")

# Which are the most influential studies?
dfbetas_dat2[abs(dfbetas_dat2[,1])>1 | abs(dfbetas_dat2[,2])>1
             | abs(dfbetas_dat2[,3])>1 | abs(dfbetas_dat2[,4])>1
             | abs(dfbetas_dat2[,5])>1 | abs(dfbetas_dat2[,6])>1,]

# hat values
hat_dat2 <- hatvalues(Q2m4) 

# Which are the most influential effects?
inf_cutoff <- 3 * length(Q2m4$beta)/nrow(dat_2)

dat_2$Study[hat_dat2 > inf_cutoff]
```

#### Data set 3: resistance vs fitness effects of environmental stress
I'm running the analysis here for the model with the lowest AIC (Q3m4). We should probably do it for which ever model is our main model in the manuscript (probably this one?)

```{r dat_3-influence}
# Cook's distance
Cook_dat3 <- cooks.distance(Q3m4, progbar=TRUE, dat_3$Study, reestimate=TRUE, parallel="multicore", ncpus = 4)

# how are these distances distributes?
hist(Cook_dat3)

# Which are the most influential studies?
Cook_dat3[which(Cook_dat3 > 3)]

# dfbetas
dfbetas_dat3 <- dfbetas.rma.mv(Q3m4, progbar=TRUE, dat_3$Study, reestimate=TRUE, parallel="multicore")

# Which are the most influential studies?
dfbetas_dat3[abs(dfbetas_dat3[,1])>1 | abs(dfbetas_dat3[,2])>1
             | abs(dfbetas_dat3[,3])>1 | abs(dfbetas_dat3[,4])>1
             | abs(dfbetas_dat3[,5])>1 | abs(dfbetas_dat3[,6])>1,]

# hat values
hat_dat3 <- hatvalues(Q3m4) 

# Which are the most influential effects?
inf_cutoff <- 3 * length(Q3m4$beta)/nrow(dat_3)

dat_3$Study[hat_dat3 > inf_cutoff]
```

# Heterogeneity

Here I take the "best" model for each question to estimate between study heterogeneity. We could potentially do the same a different model or more models, depending on our goals.

Heterogeneity is important to know if the pooled effect size can be interpreted in a meaningful way. High heterogeneity is not necessarily a bad thing, but we would at least want to know if individual study effects usually go in the direction of the pooled effect.

## I2 statistic
Is one of the most commonly reported measures of heterogeneity. It captures the "percentage of variability in the effect sizes that is not caused by sampling error". That is, heterogeneity in true effect sizes. It tells us how much true heterogeneity there is *relative* to sampling error.

### Question 1

```{r dat_1-I2}
# we account for covariance in sampling errors by using V, but assuming equal heterogeneity between fecundity vs survival and between environment, pollution and resources.

# matrix of sampling variances and covariances W 
W <- solve(varcovmat_1_PD$mat)

# model matrix
X <- model.matrix(Q1m4)

# estimate heterogeneity
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W

# overall I2: how much of total variance is attributed to heterogeneity
100 * sum(Q1m4$sigma2) / (sum(Q1m4$sigma2) + (Q1m4$k-Q1m4$p)/sum(diag(P)))

# Heterogeneity between experiments, within experiments, between parasites
100 * Q1m4$sigma2 / (sum(Q1m4$sigma2) + (Q1m4$k-Q1m4$p)/sum(diag(P)))

sav <- confint(Q1m4)
#profile(Q1m4)

# confidence intervals for I2
100 * sav[[1]]$random[1,2:3] /(sum(Q1m4$sigma2) + (Q1m4$k-Q1m4$p)/sum(diag(P))) ### CI for experiment-level I^2
100 * sav[[2]]$random[1,2:3] / (sum(Q1m4$sigma2)+ (Q1m4$k-Q1m4$p)/sum(diag(P))) ### CI for the ID-level I^2
100 * sav[[3]]$random[1,2:3] / (sum(Q1m4$sigma2) + (Q1m4$k-Q1m4$p)/sum(diag(P)))  ### CI for the parasite-level I^2
```

### Question 2

```{r dat_2-I2}
# we account for covariance in sampling errors by using V, but assuming equal heterogeneity between fecundity vs survival and between environment, pollution and resources.

# matrix of sampling variances and covariances W 
W <- solve(varcovmat_2_PD$mat)

# model matrix
X <- model.matrix(Q2m3)

# estimate heterogeneity
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W

# overall I2: how much of total variance is attributed to heterogeneity
100 * sum(Q2m3$sigma2) / (sum(Q2m3$sigma2) + (Q2m3$k-Q2m3$p)/sum(diag(P)))

# Heterogeneity between experiments, within experiments, between parasites
100 * Q2m3$sigma2 / (sum(Q2m3$sigma2) + (Q2m3$k-Q2m3$p)/sum(diag(P)))

sav2 <- confint(Q2m3)
#profile(Q2m3)

# confidence intervals for I2
100 * sav2[[1]]$random[1,2:3] /(sum(Q2m3$sigma2) + (Q2m3$k-Q2m3$p)/sum(diag(P))) ### CI for experiment-level I^2
100 * sav2[[2]]$random[1,2:3] / (sum(Q2m3$sigma2)+ (Q2m3$k-Q2m3$p)/sum(diag(P))) ### CI for the ID-level I^2
100 * sav2[[3]]$random[1,2:3] / (sum(Q2m3$sigma2) + (Q2m3$k-Q2m3$p)/sum(diag(P)))  ### CI for the parasite-level I^2
```


### Question 3

```{r dat_3-I2}
# we account for covariance in sampling errors by using V, but assuming equal heterogeneity between fecundity vs survival and between environment, pollution and resources.

# matrix of sampling variances and covariances W 
W <- solve(varcovmat_3_PD$mat)

# model matrix
X <- model.matrix(Q3m4)

# estimate heterogeneity
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W

# overall I2: how much of total variance is attributed to heterogeneity
100 * sum(Q3m4$sigma2) / (sum(Q3m4$sigma2) + (Q3m4$k-Q3m4$p)/sum(diag(P)))

# Heterogeneity between experiments, within experiments, between parasites
100 * Q3m4$sigma2 / (sum(Q3m4$sigma2) + (Q3m4$k-Q3m4$p)/sum(diag(P)))

sav2 <- confint(Q3m4)
#profile(Q3m4)

# confidence intervals for I2
100 * sav2[[1]]$random[1,2:3] /(sum(Q3m4$sigma2) + (Q3m4$k-Q3m4$p)/sum(diag(P))) ### CI for experiment-level I^2
100 * sav2[[2]]$random[1,2:3] / (sum(Q3m4$sigma2)+ (Q3m4$k-Q3m4$p)/sum(diag(P))) ### CI for the ID-level I^2
100 * sav2[[3]]$random[1,2:3] / (sum(Q3m4$sigma2) + (Q3m4$k-Q3m4$p)/sum(diag(P)))  ### CI for the parasite-level I^2
```

## Predicted effects
Another way to assess heterogeneity is to look at the random effects at the level of experiments or effect ID (the larger variance components) and see if there are specific experiments or effects that deviate from 0.

### Question 1
```{r dat_1-random_pred}

# between experiment effects
random <- ranef(Q1m4)
random_exp <- data.frame(random$Experiment)
random_exp$Experiment <- rownames(random_exp)

for (i in 1:nrow(random_exp)){
  random_exp$gr[i] <- dat_1$Gradient.category[dat_1$Experiment == random_exp$Experiment[i]][1]
} 

random_exp <- random_exp[order(random_exp$intrcpt),] 
random_exp <- random_exp[order(random_exp$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Exp_het <-
  ggplot(data = random_exp, aes(x = Experiment, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 2) +
  scale_x_discrete(limits = random_exp$Experiment) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor") +
  labs(y = "prediction interval")

Exp_het

# within experiment effects
random_id <- data.frame(random$`Experiment/ID`)
random_id$ID <- as.factor(dat_1$ID)

for (i in 1:nrow(random_id)){
  random_id$gr[i] <- dat_1$Gradient.category[i]
} 

random_id <- random_id[order(random_id$intrcpt),] 
random_id <- random_id[order(random_id$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Id_het <-
  ggplot(data = random_id, aes(x = ID, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 1) +
  scale_x_discrete(limits = random_id$ID) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor") +
  labs(y = "prediction interval")

Id_het
```

### Question 2
```{r dat_2-random_pred}

# between experiment effects
random <- ranef(Q2m3)
random_exp <- data.frame(random$Experiment)
random_exp$Experiment <- rownames(random_exp)

for (i in 1:nrow(random_exp)){
  random_exp$gr[i] <- dat_2$Gradient.category[dat_2$Experiment == random_exp$Experiment[i]][1]
} 

random_exp <- random_exp[order(random_exp$intrcpt),] 
random_exp <- random_exp[order(random_exp$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Exp_het <-
  ggplot(data = random_exp, aes(x = Experiment, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 1.5) +
  scale_x_discrete(limits = random_exp$Experiment) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor") +
  labs(y = "prediction interval")

Exp_het

# within experiment effects
random_id <- data.frame(random$`Experiment/ID`)
random_id$ID <- as.factor(dat_2$ID)

for (i in 1:nrow(random_id)){
  random_id$gr[i] <- dat_2$Gradient.category[i]
} 

random_id <- random_id[order(random_id$intrcpt),] 
random_id <- random_id[order(random_id$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Id_het <-
  ggplot(data = random_id, aes(x = ID, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 1) +
  scale_x_discrete(limits = random_id$ID) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor") +
  labs(y = "prediction interval")

Id_het
```
### Question 3
```{r dat_3-random_pred}

# between experiment effects
random <- ranef(Q3m4)
random_exp <- data.frame(random$Experiment)
random_exp$Experiment <- rownames(random_exp)

for (i in 1:nrow(random_exp)){
  random_exp$gr[i] <- dat_3$Gradient.category[dat_3$Experiment == random_exp$Experiment[i]][1]
} 

random_exp <- random_exp[order(random_exp$intrcpt),] 
random_exp <- random_exp[order(random_exp$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Exp_het <-
  ggplot(data = random_exp, aes(x = Experiment, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 1.5) +
  scale_x_discrete(limits = random_exp$Experiment) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor")  +
  labs(y = "prediction interval")

Exp_het

# within experiment effects
random_id <- data.frame(random$`Experiment/ID`)
random_id$ID <- as.factor(dat_3$ID)

for (i in 1:nrow(random_id)){
  random_id$gr[i] <- dat_3$Gradient.category[i]
} 

random_id <- random_id[order(random_id$intrcpt),] 
random_id <- random_id[order(random_id$gr),] 

pal <- wes_palette("IsleofDogs1", n = 3)
Id_het <-
  ggplot(data = random_id, aes(x = ID, colour = gr)) +
  geom_errorbar(aes(ymin = pi.lb, ymax = pi.ub), size = 1) +
  scale_x_discrete(limits = random_id$ID) +
  theme_light(base_size = 16) +
  theme(
    panel.grid.major.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_colour_manual(values = pal, name = "Stressor") +
  labs(y = "prediction interval")

Id_het
```

