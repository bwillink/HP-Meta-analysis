---
title: "Host-Parasite Meta-analysis"
author: "Amanda Vicente, Beatriz Willink, Kacy Nowak, Dave Civitello"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    number_sections: false
    toc: true
    toc_float: true
    toc_depth: 4
---

Load packages
```{r load-packages, message=FALSE, results='hide'}
x <-
  c(
    "metafor", "kableExtra", "Matrix", "dplyr", "wesanderson", "weightr", "ggplot2", "MuMIn", "RColorBrewer", "tidyverse", "patchwork", "devtools", "R.rsp")

lapply(x, function(y) {
  # check if installed, if not install
  if (!y %in% installed.packages()[, "Package"])
    install.packages(y)
  
  # load package
  try(require(y, character.only = T), silent = T)
})

#devtools::install_github("itchyshin/orchard_plot", subdir = "orchaRd", force = TRUE, build_vignettes = TRUE)
library(orchaRd)

```

Read in data
```{r read-data}
dat <- read.csv("../data/MA_dat_08-05-2021.csv", header = T, sep = ",")

# subset data that have a "variation type". We'll parse based on variation type below
#dat <- dat[-which(is.na(dat$Variation.Type) == TRUE),]
dat <- subset(dat, select = -c(Data_source,Comment)) 
colnames(dat)
  
```

# Data cleaning
*There might be more of this coming...*

## Gradient categories 
```{r}
# Toxin is a type of pollution
dat$Gradient.category <- gsub(pattern = "Toxin", replacement = "Pollution", x = dat$Gradient.category)

# exclude ambiguous/equivocal categories
dat <- dat[which(dat$Gradient.category != "Ecological"),]

# Check gradient categories 
levels(as.factor(dat$Gradient.category))

# Check pollution experiments are actually chemical pollution
levels(as.factor(dat$X_gradient[dat$Gradient.category == "Pollution"]))

# Nocturnal light and noise should be "Environment"
dat$Gradient.category[dat$X_gradient == "Noctural light"] <- "Environment"
dat$Gradient.category[dat$X_gradient == "Noise"] <- "Environment"

# Check Environment experiments are not chemical pollution
levels(as.factor(dat$X_gradient[dat$Gradient.category == "Environment"]))

# Check resource limitation experiments are actual resources
levels(as.factor(dat$X_gradient[dat$Gradient.category == "Resource"]))
```

## Median, min, max and n to mean and SD
```{r}
non_par <- dat[which(dat$Variation.Type == "Median_Min_Max"),]

# Estimate mean for control and treatment from median, maximum and minimum
non_par$Estimated_Mean_C <- (non_par$Lwr_C + 2 * non_par$Mean_C + non_par$Upr_C) / 4
non_par$Estimated_Mean_X <- (non_par$Lwr_X + 2 * non_par$Mean_X + non_par$Upr_X) / 4

# Estimate SD from range and n
# First, read in Xi_N table from Wang et al. (2014) BMC Medical Research Methodology
Xi_table <- read.csv("../scripts/Xi_N_Table.csv", header = T, sep = ",") 

# Estimate SD using the approximation for each N under 50
for (i in 1:length(non_par$ID)) {
  non_par$Estimated_SD_C[i] <-
    (non_par$Upr_C[i] - non_par$Lwr_C[i]) / Xi_table$Xi_N[which(Xi_table$N == non_par$N_C[i])]
  non_par$Estimated_SD_X[i] <-
    (non_par$Upr_X[i] - non_par$Lwr_X[i]) / Xi_table$Xi_N[which(Xi_table$N == non_par$N_X[i])]
}

# overwrite dat
dat$Mean_C[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_Mean_C 
dat$Mean_X[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_Mean_X

dat$Variation_C[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_SD_C
dat$Variation_X[which(dat$Variation.Type == "Median_Min_Max")] <- non_par$Estimated_SD_X

dat$Variation.Type[which(dat$Variation.Type == "Median_Min_Max")] <- "SD"

# Sanity check
levels(as.factor(dat$Variation.Type))
```

## Median and IQ range to mean 
```{r}
non_par_2 <- dat[which(dat$Variation.Type == "Median_IQ"),]

# Estimate mean for control and treatment from median and IQ range
non_par_2$Estimated_Mean_C <- (non_par_2$Lwr_C + non_par_2$Mean_C + non_par_2$Upr_C) / 3
non_par_2$Estimated_Mean_X <- (non_par_2$Lwr_X + non_par_2$Mean_X + non_par_2$Upr_X) / 3

# overwrite dat
dat$Mean_C[which(dat$Variation.Type == "Median_IQ")] <- non_par_2$Estimated_Mean_C 
dat$Mean_X[which(dat$Variation.Type == "Median_IQ")] <- non_par_2$Estimated_Mean_X

dat$Variation.Type[which(dat$Variation.Type == "Median_IQ")] <- "IQ"

# Sanity check
levels(as.factor(dat$Variation.Type))
```

## subset effects with workable "variation types"
```{r}
nrow(dat)

accepted_var <- c("SE", "SD", "CI", "Wald CI", "IQ", "OR")
dat <- dat[which(dat$Variation.Type %in% accepted_var),]

nrow(dat)

# store sample size in an object
N <- nrow(dat)
```

# Getting effect sizes

## Calculate OR and approximate variance from contingency tables
```{r OR}
for (i in 1:N) {
  # no correction need if none of the categories are 0
  if (dat$Variation.Type[i] == "OR" &
      dat$Success_C[i] > 0 &
      dat$Success_X[i] > 0 &
      (dat$N_C[i] - dat$Success_C[i]) > 0 &
      (dat$N_X[i] - dat$Success_X[i]) > 0) {
    dat$OR[i] <-
      (dat$Success_X[i] * (dat$N_C[i] - dat$Success_C[i])) / (dat$Success_C[i] * (dat$N_X[i] - dat$Success_X[i]))
    dat$Log.OR[i] <- log(dat$OR[i])
    # approximate variance
    dat$Log.OR.v[i] <-
      1 / dat$Success_X[i] + 1 / (dat$N_X[i] - dat$Success_X[i]) + 1 / dat$Success_C[i] + 1 / (dat$N_C[i] - dat$Success_C[i])
  }
  else {
    # if at least one category is 0, we apply Yate's correction to avoid dividing by 0
    if (dat$Variation.Type[i] == "OR" &
        (dat$Success_C[i] == 0 |
        dat$Success_X[i] == 0 |
        (dat$N_C[i] - dat$Success_C[i]) == 0 |
        (dat$N_X[i] - dat$Success_X[i]) == 0)) {
      dat$OR[i] <-
        ((dat$Success_X[i] + 0.5) * (dat$N_C[i] - dat$Success_C[i] + 0.5)) / ((dat$Success_C[i] + 0.5) * (dat$N_X[i] - dat$Success_X[i] + 0.5))
      dat$Log.OR[i] <- log(dat$OR[i])
      # approximate variance
      dat$Log.OR.v[i] <-
        1 / (dat$Success_X[i] + 0.5)  + 1 / (dat$N_X[i] - dat$Success_X[i] + 0.5) + 1 / (dat$Success_C[i] + 0.5) + 1 / (dat$N_C[i] - dat$Success_C[i] + 0.5)
    }
    else{
      # if there is no OR data, make these columns NA
      dat$OR[i] <- NA
      dat$Log.OR[i] <- NA
      dat$Log.OR.v[i] <- NA
    }
  }
}
```


## Calculate SD for comparisons with continuous normally distributed variables
```{r SD}
# create SD variables
dat$SD_C <- vector(length = N)
dat$SD_X <- vector(length = N)

for (i in 1:N) {
  # Calculate SD if SE is reported
  if (dat$Variation.Type[i] == "SE") {
    dat$SD_C[i] <- dat$Variation_C[i] * sqrt(dat$N_C[i])
    dat$SD_X[i] <- dat$Variation_X[i] * sqrt(dat$N_X[i])
  } else {
    # calculate SD if a 95% confidence interval for a normal distribution is reported
    # this also applies to the Wald confidence interval for proportions, as it is a normal approximation to the binomial
    if (dat$Variation.Type[i] == "CI" |
        dat$Variation.Type[i] == "Wald CI") {
      # calculate SE from lower and upper limits
      temp_C1 <- (dat$Upr_C[i] - dat$Mean_C[i]) / 1.96
      temp_C2 <- (dat$Mean_C[i] - dat$Lwr_C[i]) / 1.96
      
      temp_X1 <- (dat$Upr_X[i] - dat$Mean_X[i]) / 1.96
      temp_X2 <- (dat$Mean_X[i] - dat$Lwr_X[i]) / 1.96
      
      # average digitized/recorded values of SE (because we have two) and transform to SD
      dat$SD_C[i] <-
        mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_C[i])
      dat$SD_X[i] <-
        mean(abs(c(temp_C1, temp_C2))) * sqrt(dat$N_X[i])
    } else {
      # approximate SD if IQ range is reported
      if (dat$Variation.Type[i] == "IQ") {
        dat$SD_C[i] <- (dat$Upr_C[i] - dat$Lwr_C[i]) / 1.35
        dat$SD_X[i] <- (dat$Upr_X[i] - dat$Lwr_X[i]) / 1.35
      }
      else {
        # if SD is reported leave as such
        if (dat$Variation.Type[i] == "SD") {
          dat$SD_C[i] <- dat$Variation_C[i]
          dat$SD_X[i] <- dat$Variation_X[i]
        } else {
          # if there is no appropriate data, make these columns NA
          dat$SD_C[i] <- NA
          dat$SD_X[i] <- NA
        }
      }
    }
  }
}
```


## Get effect sizes and variances
```{r calculate d}
# within groups standard deviation
dat$S_within <-
  sqrt(((dat$N_C - 1) * dat$SD_C ^ 2 + (dat$N_X - 1) * dat$SD_X ^ 2) / (dat$N_C + dat$N_X - 2))

# standardized effect size
for (i in 1:N) {
  # standardized mean difference
  # we can't include data without variance
  if (is.na(dat$S_within[i]) == FALSE & dat$S_within[i] > 0) {
    dat$d[i] <- (dat$Mean_X[i] - dat$Mean_C[i]) / dat$S_within[i]
    dat$var.d[i] <-
      (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
      (2 * (dat$N_C[i] + dat$N_X[i]))
  }
  else{
    # if only F statistic is reported - no cases of this yet!
    if (dat$Variation.Type[i] == "F_X") {
      dat$d[i] <-
        sqrt(dat$F_X[i] * (dat$N_X[i] + dat$N_C[i]) / (dat$N_C[i] * dat$N_X[i]))
      dat$var.d[i] <-
        (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
        (2 * (dat$N_C[i] + dat$N_X[i]))
      
    } else{
      # if Z and N are reported for a regression analysis
      if (dat$Variation.Type[i] == "Z_reg") {
        r <- dat$Z_X[i] / sqrt(dat$Z_N[i])
        dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
        Vr <- (1 - r ^ 2) ^ 2 / (dat$Z_N[i] - 1)
        dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
      }
      else{
        # if t and N are reported for a regression analysis
        if (dat$Variation.Type[i] == "t") {
          r <- sqrt((dat$Z_X[i] ^ 2) / (dat$Z_X[i] ^ 2 + dat$Z_df[i]))
          dat$d[i] <- (2 * r) / (sqrt(1 - r ^ 2))
          Vr <- (1 - r ^ 2) ^ 2 / (dat$R_N[i] - 1)
          dat$var.d[i] <- (4 * Vr) / (1 - r ^ 2) ^ 3
        }
        else{
          # If Z is reported from a comparison of two independent groups
          if (dat$Variation.Type[i] == "Z") {
            dat$d[i] <-
              sqrt(abs(dat$Z_X[i]) * sqrt(dat$N_C[i] + dat$N_X[i]) / (1 - sqrt(
                dat$Z_X[i] ^ 2 * (dat$N_C[i] + dat$N_X[i]) ^ -1
              )))
            dat$var.d[i] <-
              (dat$N_C[i] + dat$N_X[i]) / (dat$N_C[i] * dat$N_X[i]) + (dat$d[i] ^ 2) /
              (2 * (dat$N_C[i] + dat$N_X[i]))
          }
          else{
            # converting log OR
            if (is.na(dat$Log.OR.v[i]) == FALSE &
                dat$Log.OR.v[i] > 0) {
              dat$d[i] <- dat$Log.OR[i] * (sqrt(3) / pi)
              dat$var.d[i] <- dat$Log.OR.v[i] * 3 / pi ^ 2
            } else {
              # for now, leave other types of effects as NA
              dat$d[i] <- NA
              dat$var.d[i] <- NA
            }
          }
        }
      }
    }
  }
}
```


## Correct for sample size and get g
```{r calculate g}
# sample size correction factor
for (i in 1:N) {
  # if odds ratio or comparison between means
  if (is.na(dat$N_C[i]) == F) {
    dat$J[i] <- 1 - 3 / (4 * (dat$N_C[i] + dat$N_X[i] - 2) - 1)
  } else {
    # if correlation
    if (is.na(dat$R_N[i]) == F) {
      dat$J[i] <- 1 - 3 / (4 * (dat$R_N[i] - 2) - 1)
    }else {
      dat$J[i] <- NA
    }
  }
}
# corrected effect size
dat$g <- dat$J * dat$d

# and variance
dat$var.g <- (dat$J ^ 2) * dat$var.d
```

## flip effect sizes for remaining mortality effects
```{r standardize-survival}
mort <- grep(pattern = "[M,m]ort", x = dat$Trait)

for(i in mort){
  dat$g[i] <- -dat$g[i]
}
```

## flip effect sizes for prevalence and intensity
```{r flip-effect-resistance}
resist <- grep(pattern = "Intensity|Prevalence", x = dat$Trait.type)

for(i in resist){
  dat$g[i] <- -dat$g[i]
}
```

# Prepare data
Filter experiments with both epidemiological and infected demographic effects
```{r divide-datasets}
# For now, get rid of NAs
dat <- dat[(is.na(dat$d) == F),]

# How many experiments do we have?
Exps <- unique(dat$Experiment)

# A data frame of experiments that included Infected demographic and Uninfected demographic effects
dat_1 <- data.frame()

# A data frame of experiments that included Infected demographic and Epidemiological effects
dat_2 <- data.frame()

# populate data sets with corresponding experiments
for (i in Exps) {
  tmp <- dat[which(dat$Experiment == i), ]
  if ("Uninfected demographic" %in% tmp$Trait.category &
      "Infected demographic" %in% tmp$Trait.category) {
    dat_1 <- rbind(dat_1, tmp)
  }
  if ("Epidemiological" %in% tmp$Trait.category &
      "Infected demographic" %in% tmp$Trait.category) {
    dat_2 <- rbind(dat_2, tmp)
  }
}

dat_1 <- dat_1[which(dat_1$Trait.category == "Uninfected demographic" | dat_1$Trait.category == "Infected demographic"),]

dat_2 <- dat_2[which(dat_2$Trait.category == "Epidemiological" | dat_2$Trait.category == "Infected demographic"),]

dat_2$Trait.type <- factor(dat_2$Trait.type, levels = c("Prevalence", "Intensity", "Fecundity", "Survivorship"), ordered = T)

```

## Variance-covariance of sampling errors matrix (for multiple comparisons)
This code produces a variance-covariance of sampling errors matrix, n x n, with n = number of effect sizes. It requires the dataset (dat), Hedge's g (g), and the variance of Hedge's g (var.g) to be defined above. It uses "Experiment", "Level_C", "Trait", "N_C", and "N_X" columns.


### Identify negative eigenvalues
First, we find out which studies have negative eigenvalues in their variance-covar matrix. This means covariance between treatment effects with the same control is larger than variance and it's an indicator of suspiciously low variance and potentially an incorrectly reported N or an error while digitizing data.

For data set 1
```{r check-var-covar_1}
studies_1 <- unique(dat_1$Study)
studies_to_check <- c()
negative_eigen <- c()

for (k in studies_1) {
  dat_study <- dat_1[which(dat_1$Study == k),]
  varcovmat = matrix(0,
                     nrow = dim(dat_study)[1],
                     ncol = dim(dat_study)[1])
  
  for (i in 1:dim(dat_study)[1]) {
    for (j in 1:dim(dat_study)[1]) {
      if (i == j) {
        varcovmat[i, j] = dat_study$var.g[i]
      } else{
        if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
            dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
            dat_study[i, "Trait"] == dat_study[j, "Trait"] &
            dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
          varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
            (dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
        }
      }
    }
  }
  
  val <- eigen(varcovmat)
  for (m in 1:length(val$values)) {
    if (val$values[m] < 0) {
    studies_to_check <- append(studies_to_check, k)
    negative_eigen <- append(negative_eigen, val$values[m])
    }
  }
}
    
Neg_eigen_1 <- data.frame(study = studies_to_check, eigen = negative_eigen)

Neg_eigen_1 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```


For data set 2
```{r check-var-covar_2}
studies_2 <- unique(dat_2$Study)
studies_to_check <- c()
negative_eigen <- c()

for (k in studies_2) {
  dat_study <- dat_2[which(dat_2$Study == k),]
  varcovmat = matrix(0,
                     nrow = dim(dat_study)[1],
                     ncol = dim(dat_study)[1])
  
  for (i in 1:dim(dat_study)[1]) {
    for (j in 1:dim(dat_study)[1]) {
      if (i == j) {
        varcovmat[i, j] = dat_study$var.g[i]
      } else{
        if (dat_study[i, "Experiment"] == dat_study[j, "Experiment"] &
            dat_study[i, "Level_C"] == dat_study[j, "Level_C"] &
            dat_study[i, "Trait"] == dat_study[j, "Trait"] &
            dat_study[i, "Trait.category"] == dat_study[j, "Trait.category"]) {
          varcovmat[i, j] = 1 / dat_study[i, "N_C"] + dat_study$g[i] * dat_study$g[j] /
            (dat_study[i, "N_C"] + dat_study[i, "N_X"] + dat_study[j, "N_X"])
        }
      }
    }
  }
  
  val <- eigen(varcovmat)
  for (m in 1:length(val$values)) {
    if (val$values[m] < 0) {
    studies_to_check <- append(studies_to_check, k)
    negative_eigen <- append(negative_eigen, val$values[m])
    }
  }
}
    
Neg_eigen_2 <- data.frame(study = studies_to_check, eigen = negative_eigen)

Neg_eigen_2 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

Based on these eigenvalues, we looked back at the studies/experiments and determined if they had issues with reporting N or variance. We decided to remove two such studies for data set 1 (Ashraf et al. 2017 and Shostak et al. 2015) and one such study for data set 2 & 3 (Ashraf et al. 2017). 

As we found no errors or causes of concern for other studies with barely negative eigenvalues, we are forcing the var-covar matrices to the nearest positive definite values, while keeping the diagonals (var) to the estimated values and modifying only the expected covariances.

Also for now we are excluding Experiment 121 from Civitello et al 2020 Proc. B. This study has a relatively low variance for the control of the uninfected demographic fecundity effects, which results in a negative eigenvalue.

```{r var-covar-matrix}
# exclude suspicious studies with highly negative eigenvalues
dat_1 <- dat_1[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_1$Study),]
dat_1 <- dat_1[-grep("Shostak et al. 2015. Journal of Parasitology", dat_1$Study),]
dat_1 <- dat_1[-grep(121, dat_1$Experiment),]

varcovmat_1 = matrix(0, nrow = dim(dat_1)[1], ncol = dim(dat_1)[1])

for (i in 1:dim(dat_1)[1]) {
  for (j in 1:dim(dat_1)[1]) {
    if (i == j) {varcovmat_1[i,j] = dat_1$var.g[i]}else{
      if (dat_1[i, "Experiment"] == dat_1[j, "Experiment"] & dat_1[i, "Level_C"] == dat_1[j, "Level_C"] & dat_1[i, "Trait"] == dat_1[j, "Trait"] & dat_1[i, "Trait.category"] == dat_1[j, "Trait.category"]) {
        varcovmat_1[i,j] = 1/dat_1[i,"N_C"] + dat_1$g[i]*dat_1$g[j]/(dat_1[i,"N_C"] + dat_1[i,"N_X"] + dat_1[j,"N_X"]) 
      }
    }
  }
}

# correct negative eigens in the few studies with large covar to var ratios
varcovmat_1_PD <- nearPD(varcovmat_1,  keepDiag = TRUE)


# exclude suspicious studies with highly negative eigenvalues
dat_2 <- dat_2[-grep("Ashraf et al. 2017 Environ Sci Pollut Res", dat_2$Study),]

# Carrington et al. 2013 has extremely large sampling variance for a parasite prevalence effect. DOUBLE CHECK!!!
dat_2 <- dat_2[-grep("Carrington et al. 2013. PLOS NegTropDiseases", dat_2$Study),]

varcovmat_2 = matrix(0, nrow = dim(dat_2)[1], ncol = dim(dat_2)[1])

for (i in 1:dim(dat_2)[1]) {
  for (j in 1:dim(dat_2)[1]) {
    if (i == j) {varcovmat_2[i,j] = dat_2$var.g[i]}else{
      if (dat_2[i, "Experiment"] == dat_2[j, "Experiment"] & dat_2[i, "Level_C"] == dat_2[j, "Level_C"] & dat_2[i, "Trait"] == dat_2[j, "Trait"] & dat_2[i, "Trait.category"] == dat_2[j, "Trait.category"]) {
        varcovmat_2[i,j] = 1/dat_2[i,"N_C"] + dat_2$g[i]*dat_2$g[j]/(dat_2[i,"N_C"] + dat_2[i,"N_X"] + dat_2[j,"N_X"]) 
      }
    }
  }
}  

# correct eigenvalues in the few studies with large covar to var ratios
varcovmat_2_PD <- nearPD(varcovmat_2, keepDiag = TRUE)

```

Create a new column with a category of vertebrate or invertebrate (keeping this for now)
```{r vertebrate/invertebrate host category, echo=FALSE}
dat_1 <- mutate(dat_1, Host.type.2 = case_when(
  Host.type == "Fish" ~ "Vertebrate",
  Host.type == "Arthropod" ~ "Invertebrate",
  Host.type == "Amphibian" ~ "Vertebrate",
  Host.type == "Mollusc" ~ "Invertebrate"))

dat_2 <- mutate(dat_2, Host.type.2 = case_when( 
  Host.type == "Fish" ~ "Vertebrate",
  Host.type == "Arthropod" ~ "Invertebrate",
  Host.type == "Amphibian" ~ "Vertebrate",
  Host.type == "Mollusc" ~ "Invertebrate",
  Host.type == "Reptile" ~ "Vertebrate",
  Host.type == "Bird" ~ "Vertebrate",
  Host.type == "Mammal" ~ "Vertebrate"))

```

Create a new column collapsing pollution and environmental stress
```{r pollution/environment stress category, echo=FALSE}
dat_1 <- mutate(dat_1, Gradient.category.2 = case_when(
  Gradient.category == "Pollution" ~ "Environment",
  Gradient.category == "Environment" ~ "Environment",
  Gradient.category == "Resource" ~ "Resource"))

dat_2 <- mutate(dat_2, Gradient.category.2 = case_when( 
  Gradient.category == "Pollution" ~ "Environment",
  Gradient.category == "Environment" ~ "Environment",
  Gradient.category == "Resource" ~ "Resource"))

```

# Numbers mentioned in the methods
The Methods section describes various features of the data, indicating the number of studies/effects with those features. Numbers are calculated here. 

```{r}
# First, get all the curated data
final_dat <- merge(dat_2, dat_1, all = T )
nrow(final_dat)

# do we have any observational studies left after filtering?
levels(as.factor(final_dat$Study.type))

# Number of studies that report median instead of mean
c(unique(non_par$Study), unique(non_par_2$Study)) %in% final_dat$Study
length(unique(non_par$Study)) + length(unique(non_par_2$Study)) 
length(non_par$ID) + length(non_par_2$ID) 

# number of studies with only data range
length(non_par$ID)
length(unique(non_par$Study))

# number of studies with only IQ
length(non_par_2$ID)
length(unique(non_par_2$Study))

# number of studies with OR
length(unique(final_dat$Study[final_dat$Variation.Type == "OR"]))

# number or studies w/ multiple treatment levels or measuring time points
k = c()
for(i in 2:nrow(final_dat)){
 if(final_dat$Trait[i] == final_dat$Trait[i-1] &
    final_dat$X_gradient[i] == final_dat$X_gradient[i-1] &
    final_dat$Host[i] == final_dat$Host[i-1] &
    final_dat$Parasite[i] == final_dat$Parasite[i-1]) {
   k <- append(k, final_dat$Experiment[i])
    }
}
length(unique(k))

# studies with negative eigen values
sum(unique(c(Neg_eigen_1$eigen,Neg_eigen_2$study)) %in% final_dat$Study == T)

# how many experiments
length(unique(final_dat$Experiment))

# how many studies include more than one experiment
k = c()
for(i in 2:nrow(final_dat)){
 if(final_dat$Experiment[i] != final_dat$Experiment[i-1] &
    final_dat$Study[i] == final_dat$Study[i-1]) {
   k <- append(k, final_dat$Study[i])
    }
}
length(unique(k))

# how many species per taxonomic groups
length(unique(final_dat$Host[final_dat$Host.type == "Arthropod"]))
length(unique(final_dat$Host[final_dat$Host.type == "Mollusc"]))
length(unique(final_dat$Host[final_dat$Host.type == "Fish"]))
length(unique(final_dat$Host[final_dat$Host.type == "Amphibian"]))
length(unique(final_dat$Host[final_dat$Host.type == "Reptile"]))
length(unique(final_dat$Host[final_dat$Host.type == "Bird"]))
length(unique(final_dat$Host[final_dat$Host.type == "Mammal"]))

length(unique(final_dat$Parasite[final_dat$Parasite.type == "Bacteria"]))
length(unique(final_dat$Parasite[final_dat$Parasite.type == "Fungus"]))
length(unique(final_dat$Parasite[final_dat$Parasite.type == "Helminth"]))
length(unique(final_dat$Parasite[final_dat$Parasite.type == "Myxozoa"]))
length(unique(final_dat$Parasite[final_dat$Parasite.type == "Protozoan"]))
length(unique(final_dat$Parasite[final_dat$Parasite.type == "Virus"]))
```

# Analysis

## Question 1 - Is there a differencial response to stressors between infected and uninfected host?
### Model selection
```{r Model selection Q1}
# First, we evaluate some code that generates helper functions needed so that metafor and MuMIn could interact as necessary
eval(metafor:::.MuMIn)

# Now, we take the full model and fit the rest of the models and examine those models whose AICc value is no more than 10 units away from that of the best model
full_model.1 <- rma.mv(
    g,
    V = varcovmat_1_PD$mat,
    mods = ~ Trait.category*Trait.type*Gradient.category, 
    random = list( ~ 1 | Experiment,  ~ 1 | ID),
    data = dat_1,
    method = "ML"
  )

model_selection.1 <- dredge(full_model.1, trace = 2) 
subset(model_selection.1, delta <= 10, recalc.weights = FALSE)

# relative importance values for the predictors can be obtained with:
importance(model_selection.1)
```

### Full Model
We fit the full model to show there is no effect of infection status
```{r Q1 full model, message=FALSE}
Q1.f <-
  rma.mv(
    g ~ Trait.category:Trait.type:Gradient.category -1,
    V = varcovmat_1_PD$mat,
    random = list(~ 1 | Experiment,  ~ 1 | ID),
    data = dat_1,
    method = "REML"
  )

pal <- RColorBrewer::brewer.pal(6,"Spectral")

Q1.f_OP <-
  orchard_plot(
    Q1.f,
    xlab = "Standardised mean difference (Hedge's g)",
    transfm = "none",
    angle = 0,
    alpha = 0.7
  ) +
  scale_fill_manual(values = rep(pal, each = 2)) + scale_colour_manual(values = rep(pal, each = 2)) +
  scale_y_discrete(
    labels = c(
      "Infected:EE:fecund",
      "Uninfected:EE:fecund",
      "Infected:EE:surv",
      "Uninfected:EE:surv",
      "Infected:CP:fecund",
      "Uninfected:CP:fecund",
      "Infected:CP:surv",
      "Uninfected:CP:surv",
      "Infected:RL:fecund",
      "Uninfected:RL:fecund",
      "Infected:RL:surv",
      "Uninfected:RL:surv"
    )
  )

Q1.f_OP
```

### Best Model: Effects in  survival vs fecundity under different types of stress, combining infected and uninfected
```{r Q1 Best model}
Q1 <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1 ,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment, ~ 1 | ID),
    data = dat_1,
    method = "REML"
  )

summary(Q1)
forest.default(x= Q1$beta, sei =  Q1$se, ci.lb =  Q1$ci.lb, ci.ub =  Q1$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("Environment fecundity", "Environment survivorship", "Pollution  fecundity", "Pollution  survivorship", "Resource  fecundity", "Resource  survivorship"))
```

Make Table 2 with results from Q1

```{r Q1 Results table}

Table2 <- data.frame(Stressor_type = c("endogenous environment", "endogenous environment", "chemical pollution", "chemical pollution", "resource limitation","resource limitation"),
                     Response_trait = c(rep(c("fecundity", "survivorship"), 3)),
                     Overall_mean = round(Q1$beta,3),
                     Lower_95 = round(Q1$ci.lb,3),
                     Upper_95 = round(Q1$ci.ub,3),
                     P_value = round(Q1$pval,3),
                     N_effects = c(length(dat_1$ID[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Fecundity"]),
                                   length(dat_1$ID[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Survivorship"]),
                                   length(dat_1$ID[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Fecundity"]),
                                   length(dat_1$ID[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Survivorship"]),
                                   length(dat_1$ID[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Fecundity"]),
                                   length(dat_1$ID[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Survivorship"])),
                     N_experiments = c(length(unique(dat_1$Experiment[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Experiment[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Survivorship"])),
                                   length(unique(dat_1$Experiment[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Experiment[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Survivorship"])),
                                   length(unique(dat_1$Experiment[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Experiment[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Survivorship"]))
),
N_host_taxa = c(length(unique(dat_1$Host[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Host[dat_1$Gradient.category == "Environment" & dat_1$Trait.type == "Survivorship"])),
                                   length(unique(dat_1$Host[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Host[dat_1$Gradient.category == "Pollution" & dat_1$Trait.type == "Survivorship"])),
                                   length(unique(dat_1$Host[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Fecundity"])),
                                   length(unique(dat_1$Host[dat_1$Gradient.category == "Resource" & dat_1$Trait.type == "Survivorship"]))
))

rownames(Table2) <- NULL

Table2 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

Make Figure 2 with the results of the best model for Q1

```{r Q1 best Orchard Plot}
pal <- RColorBrewer::brewer.pal(11,"Spectral")

Q1_OP <-
  orchard_plot(
    Q1,
    xlab = "Standardised mean difference (Hedge's g)",
    transfm = "none",
    angle = 0,
    alpha = 0.7
  ) +
  scale_fill_manual(values = rep(pal[c(8,11,5)], each = 2)) + scale_colour_manual(values = rep(pal[c(8,11,5)], each = 2)) +
  scale_y_discrete(
    labels = c("EE:fecundity",
               "EE:survivorship",
               "CP:fecundity",
               "CP:survivorship",
               "RL:fecundity",
               "RL:survivorship"))

Q1_OP
```
#### RVE
We check if our results are qualitatively similar if we use the robust variance estimator insteed of the vara-covar matrix for effects estimated in the same experiment.

```{r Q1 best RVE}
Q1.R <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1 ,
    V = dat_1$var.g,
    random = list( ~ 1 | Experiment, ~ 1 | ID),
    data = dat_1,
    method = "REML"
  )

Q1.R_est <- clubSandwich::coef_test(Q1.R, vcov = "CR2")

forest.default(x= Q1.R_est$beta, sei =  Q1.R_est$SE, pch = 19,
                annotate=TRUE, showweights=F, header=c("Parameter", "Estimate [95% CI]"), 
                slab = c("EE:fecundity", "EE:survivorship", "CP:fecundity", "CP:survivorship", "RL:fecundity", "RL:survivorship"), 
               xlab = "Standardised mean difference (Hedge's g)")
```


## Question 2 - Do resistance and fitness traits have different sensitivity to stressors?
### Model selection
#### All stressors
```{r Model selection Q2}
full_model.2 <- rma.mv(
    g,
    V = varcovmat_2_PD$mat,
    mods = ~ Trait.type*Gradient.category, 
    random = list( ~ 1 | Experiment,  ~ 1 | ID),
    data = dat_2,
    method = "ML"
  )

# Define if using Trait.type or Trait.category
model_selection.2 <- dredge(full_model.2, trace = 2) 
subset(model_selection.2, delta <= 10, recalc.weights = FALSE)

# relative importance values for the predictors can be obtained with:
importance(model_selection.2)
```

#### Merge Pollution and Environmental stressors 
```{r}
full_model.2.merged <- rma.mv(
    g,
    V = varcovmat_2_PD$mat,
    mods = ~ Trait.type*Gradient.category.2, 
    random = list(~ 1 | Experiment,  ~ 1 | ID),
    data = dat_2,
    method = "ML"
  )
# Define if using Trait.type or Trait.category
model_selection.2.merged <- dredge(full_model.2.merged, trace = 2) 
subset(model_selection.2.merged, delta <= 10, recalc.weights = FALSE)

# relative importance values for the predictors can be obtained with:
importance(model_selection.2.merged)

```

#### Resistance versus fitness traits 
```{r}
full_model.2.rvf <- rma.mv(
    g,
    V = varcovmat_2_PD$mat,
    mods = ~ Trait.category*Gradient.category, 
    random = list( ~ 1 | Experiment,  ~ 1 | ID),
    data = dat_2,
    method = "ML"
  )
# Define if using Trait.type or Trait.category
model_selection.2.rvf <- dredge(full_model.2.rvf, trace = 2) 
subset(model_selection.2.rvf, delta <= 10, recalc.weights = FALSE)

# relative importance values for the predictors can be obtained with:
importance(model_selection.2.rvf)

```

### Best model: Trait type x Gradient category interaction (lowest AICc)
```{r Q2 best model}
Q2 <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1,
    V = varcovmat_2_PD$mat,
    random = list(~ 1 | Experiment,  ~ 1 | ID),
    data = dat_2,
    method = "REML",
)

summary(Q2)
forest.default(x= Q2$beta, sei =  Q2$se, ci.lb =  Q2$ci.lb, ci.ub =  Q2$ci.ub, 
                annotate=TRUE, showweights=T, header=F,
                slab = c("EE:prevalence", "EE:intensity","EE:fecundity", "EE:survivorship",
               "CP:prevalence", "CP:intensity","CP:fecundity", "CP:survivorship",
               "RL:prevalence", "RL:intensity","RL:fecundity","RL:survivorship"))
```

```{r Q2 best Orchard Plot}
par_short <- c("EE:prevalence", "EE:intensity","EE:fecundity", "EE:survivorship",
               "CP:prevalence", "CP:intensity","CP:fecundity", "CP:survivorship",
               "RL:prevalence", "RL:intensity","RL:fecundity","RL:survivorship")

pal <- RColorBrewer::brewer.pal(11,"Spectral")

Q2_OP <-
  orchard_plot(
    Q2,
    xlab = "Standardised mean difference (Hedge's g)",
    transfm = "none",
    angle = 0,
    alpha = 0.7
  ) +
  scale_fill_manual(values = rep(pal[c(7,8,10,11,5,4)], each = 2)) +
  scale_colour_manual(values = rep(pal[c(7,8,10,11,5,4)], each = 2)) +
  scale_y_discrete(labels = par_short)

Q2_OP
```
#### Contrasts
Wald-type chi-square tests contrasting resistance vs fitness effects on infected hosts.
```{r resistance vs fitness contrasts adjusted}
# Environment
# Prevalence vs Fecundity
anova(Q2, X=c(-1,0,1,0,0,0,0,0,0,0,0,0))
# Prevalence vs Survivorship
anova(Q2, X=c(-1,0,0,1,0,0,0,0,0,0,0,0))
# Intensity vs Fecundity
anova(Q2, X=c(0,-1,1,0,0,0,0,0,0,0,0,0))
# Intensity vs Survivorship
anova(Q2, X=c(0,-1,0,1,0,0,0,0,0,0,0,0))

# Pollution
# Prevalence vs Fecundity
anova(Q2, X=c(0,0,0,0,-1,0,1,0,0,0,0,0))
# Prevalence vs Survivorship
anova(Q2, X=c(0,0,0,0,-1,0,0,1,0,0,0,0))
# Intensity vs Fecundity
anova(Q2, X=c(0,0,0,0,0,-1,1,0,0,0,0,0))
# Intensity vs Survivorship
anova(Q2, X=c(0,0,0,0,0,-1,0,1,0,0,0,0))

# Resources
# Prevalence vs Fecundity
anova(Q2, X=c(0,0,0,0,0,0,0,0,-1,0,1,0))
# Prevalence vs Survivorship
anova(Q2, X=c(0,0,0,0,0,0,0,0,-1,0,0,1))
# Intensity vs Fecundity
anova(Q2, X=c(0,0,0,0,0,0,0,0,0,-1,1,0))
# Intensity vs Survivorship
anova(Q2, X=c(0,0,0,0,0,0,0,0,0,-1,0,1))
```

```{r Q2 Results table}

Table3 <- data.frame(Stressor_type = rep(c("endogenous environment",  "chemical pollution","resource limitation"), each = 4),
                     Response_trait = c(rep(c("prevalence","intensity","fecundity", "survivorship"), 3)),
                     Overall_mean = round(Q2$beta,3),
                     Lower_95 = round(Q2$ci.lb,3),
                     Upper_95 = round(Q2$ci.ub,3),
                     P_value = round(Q2$pval,3),
                     N_effects = c(length(dat_2$ID[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Prevalence"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Intensity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Fecundity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Survivorship"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Prevalence"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Intensity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Fecundity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Survivorship"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Prevalence"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Intensity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Fecundity"]),
                                   length(dat_2$ID[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Survivorship"])),
                     N_experiments = c(length(unique(dat_2$Experiment[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Prevalence"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Intensity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Fecundity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Survivorship"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Prevalence"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Intensity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Fecundity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Survivorship"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Prevalence"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Intensity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Fecundity"])),
                                   length(unique(dat_2$Experiment[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Survivorship"]))
),
N_host_taxa = c(length(unique(dat_2$Host[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Prevalence"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Intensity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Fecundity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Environment" & dat_2$Trait.type == "Survivorship"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Prevalence"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Intensity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Fecundity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Pollution" & dat_2$Trait.type == "Survivorship"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Prevalence"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Intensity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Fecundity"])),
                length(unique(dat_2$Host[dat_2$Gradient.category == "Resource" & dat_2$Trait.type == "Survivorship"]))
))

rownames(Table3) <- NULL

Table3 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

#### RVE
We check if our results are qualitatively similar if we use the robust variance estimator insteed of the var-covar matrix for effects estimated in the same experiment.

```{r Q2 best RVE}
Q2.R <-
  rma.mv(
    g ~ Trait.type:Gradient.category -1,
    V = dat_2$var.g,
    random = list(~ 1 | Experiment,  ~ 1 | ID),
    data = dat_2,
    method = "REML",
)


Q2.R_est <- clubSandwich::coef_test(Q2.R, vcov = "CR2")

forest.default(x= Q2.R_est$beta, sei =  Q2.R_est$SE, pch = 19,
                annotate=TRUE, showweights=F, header=c("Parameter", "Estimate [95% CI]"), 
                slab = c("EE:prevalence", "EE:intensity", "EE:fecundity", "EE:survivorship", "CP:prevalence", "CP:intensity", "CP:fecundity", "CP:survivorship", "RL:prevalence", "RL:intensity", "RL:fecundity", "RL:survivorship"), 
               xlab = "Standardised mean difference (Hedge's g)")
```

# Heterogeneity

Here I take the "best" model for each question to estimate between study heterogeneity. We could potentially do the same a different model or more models, depending on our goals.

Heterogeneity is important to know if the pooled effect size can be interpreted in a meaningful way. High heterogeneity is not necessarily a bad thing, but we would at least want to know if individual study effects usually go in the direction of the pooled effect.

## I2 statistic
Is one of the most commonly reported measures of heterogeneity. It captures the "percentage of variability in the effect sizes that is not caused by sampling error". That is, heterogeneity in true effect sizes. It tells us how much true heterogeneity there is *relative* to sampling error.

### I2 formula

```{r}
#' @title Parametric simulation 
#' @description Function for calculating I2 estimates using parametric simulations of model estimates taken from metafor. Note that the effectiveness of these simulations depends on the accuracy of model variance estimates.
#' @param estimate The estimate (i.e. variance) from a metafor model
#' @param sims The number of simulations 
#' @param n The sample size used in estimating the variance 
#' @author Daniel Noble - daniel.noble@anu.edu.au
#' @export
simMonteCarlo <- function(estimate, n, sims){
  tmp <- data.frame(num = base::rep(1:sims, each = n), 
                    y = stats::rnorm(n*sims, 0, base::sqrt(estimate)))
  Var <- tmp %>% dplyr::group_by(num) %>% dplyr::summarise(Mean_var = stats::var(y))
  return(as.numeric(Var$Mean_var))
}

## NOTE about PIPE: Run usethis::use_pipe() in the console. The package usethis will add what you need to import the pipe to your NAMESPACE and it will also drop warnings in checks

# Function for  rounding a data frame
round_df <- function(x, digits) {
  numeric_columns <- sapply(x, class) == 'numeric'
  x[numeric_columns] <-  round(x[numeric_columns], digits)
  x
}

# Function for estimating I2 
I2 <- function(model, v, ME = FALSE, sims = 1500, phylo = FALSE, obs = FALSE){
  
  if(class(model) != "rma.mv" && class(model) != "rma"){
    stop("The model object is not of class 'metafor'")
  }
  
  wi <- 1/v  #weight
  Vw <- sum((wi) * (length(wi) - 1))  / (((sum(wi)^2) - sum((wi)^2)))
  
  if("rma.mv" %in% class(model) | "rma" %in% class(model)){
    # Monte Carlo Simulations
    # From metafor extract the important statistics
    sigma2 <- matrix(model$sigma2, nrow = 1, ncol = length(model$sigma2))
    colnames(sigma2) <- model$s.names
    sigmaN <- model$s.nlevels
    
    if(obs == FALSE){
      stop("Please add the name of the observation-level random effect, obs. If models do not include this, re-run models including (~1|obs) in the random effect list")
    }
    
    #For each variance estimate use Monte Carlo simulation of data
    Sims <- data.frame(mapply(function(x,y) simMonteCarlo(x, y, sims = sims), x = sigma2, y = sigmaN))
    colnames(Sims) <- colnames(sigma2) 
    
    #Calculate total variance
    VT <- rowSums(cbind(Sims, Vw))
    Vt <- rowSums(Sims)  # remove Vw
    
    # For each variance component divide by the total variance. Note this needs to be fixed for phylo, but does deal with variable random effects.
    I2_re <- Sims / VT
    I2_total <- data.frame(Vt / VT)
    
    tmpMatrix <- data.frame(I2_re[, -match("ID", colnames(I2_re))], total = I2_total)
    names(tmpMatrix) = c(colnames(I2_re)[!colnames(I2_re) %in% 'ID'], 'total')
      
    CI <- lapply(tmpMatrix, function(x) stats::quantile(x, c(0.025, 0.975), na.rm = TRUE))
    I_CI <- as.data.frame(do.call(rbind, CI))
    colnames(I_CI) <- c("2.5% CI", "97.5% CI")
    I2_table <- cbind(I2_Est. = colMeans(tmpMatrix), I_CI )
    
    class(I2_table) <- c("metaAidR", "data.frame")
    
    return(round_df(I2_table, digits = 4))
  }
}
```


### Question 1
First  I calculate I2 using the formula above from Nakagawa and Santos (2012) for the model without the var-covar matrix

```{r  dat_1-I2-RVE}
I2.Q1 <- I2(Q1.R, v = dat_1$var.g, obs = "ID")*100
I2.Q1
```

### Question 2
First  I calculate I2 using the formula above from Nakagawa and Santos (2012) for the model without the var-covar matrix

```{r  dat_2-I2-RVE}
I2.Q2 <- I2(Q2.R, v = dat_2$var.g, obs = "ID")*100
I2.Q2
```


# Publication bias

The most common way to assess publication bias is to test whether studies with large standard errors/low precision/small sample size tend to have larger effect sizes. Small studies have larger SEs, and because they are small, they are more likely to get published only if results are significant. In contrast, large studies, which have higher precision and have costed more money, are more likely to get published either way. For this reason small studies can cause publication bias. 

### Funnel plots
A very common way to assess publication bias is therefore to check whether studies with low precision generally have larger effects. The typical way to visualize this is through a funnel plot with all effects. Now, this is not entirely correct for us, as the effects are not independent. Nakagawa et al 2021 (Methods Ecol Evol) suggest using conditional residuals for funnel plots. These residual plots take some of the non-independence into account, but are not perfect, as they assume: 1)sampling SE(sei) does not covary with moderators in meta-regression, 2) sampling SE is the same as the SE of the residuals and 3) sampling variances are not correlated. This last one is most certainly incorrect.

Estimation of conditional residuals is not available to rma.mv objects (which can include a sampling variance-covariance matrix). The available alternative is to ignore this covariation in sampling variance for the assessment of publication bias. This is a caveat that should be acknowledgend in the paper, yet I think it is a useful visualization nonetheless. To do these funnel plots I re-fit the best model as rma.uni for each data set. While not ideal, this the best current alternative suggested by Nakagawa et al 2021 (Methods Ecol Evol)

**Note** I checked some previous studies that use multilevel regression models as we do here, to see what they do about publication bias. Sauer et al 2020 Ecology (101) acknowledged this problem and decided not to even show funnel plots: "Because of the complex non independence among effect sizes within a study (e.g., some studies had multiple effect sizes), we did not use funnel plots or rank correlation tests to assess publication bias (Lau et al. 2006, Civitello et al.2015)." Others (Yates et al. 2019 Environmental DNA (1); Salerno et al 2021 Global Change Biology (27); Brlik et al. 2020 JAE) acknowledge this problem, but still show funnel plots warning caution. They also conduct a version of Eggerts test somewhat in the same spirit as I do below.

#### Data set 1: fitness effects of environmental stress
```{r dat_1-funnel}
# re fit as a mixed effects model with rma.uni
# any fitting method other than "FE" works for a random/mixed effects model
Q1.uni <-
  rma.uni(
    g ~ Trait.type:Gradient.category + Experiment + ID ,
    vi = dat_1$var.g,
    data = dat_1,
    method = "REML"
  )

# get conditional residuals (residuals for each effect)
Q1res <- rstandard.rma.uni(Q1.uni, type = "conditional")

# create colour palette as  gradient of effect size g
nlvl <- length(dat_1$g)
pal <- colorRampPalette(brewer.pal(9, "YlOrRd"))(nlvl)
pal <-pal[order(match(pal,dat_1$g))]

# plot funnel with conditional residuals
metafor::funnel(Q1res$resid, sqrt(dat_1$var.g), level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal, back = "white", refline=0, legend=TRUE, xlab = "Conditional residual", ylab = "Standard error")
```

We can see that as SE increases (e.g ~ 1) all studies report large negative fitness effects of environmental stress (large negative residuals). In other words, it seems that very small studies tend to find that environmental stress is more negative to fitness!

#### Data set 2: resistance and fitness effects of environmental stress
```{r dat_2-funnel}
# re fit as a mixed effects model with rma.uni
# any fitting method other than "FE" works for a random/mixed effects model
Q2.uni <-
  rma.uni(
    g ~ Trait.type:Gradient.category + Experiment + ID,
    vi = dat_2$var.g,
    data = dat_2,
    method = "REML"
  )

# get conditional residuals (residuals for each effect)
Q2res <- rstandard.rma.uni(Q2.uni, type = "conditional")

# create colour palette as  gradient of effect size g
nlvl <- length(dat_2$g)
pal <- colorRampPalette(brewer.pal(9, "YlOrRd"))(nlvl)
pal <-pal[order(match(pal,dat_2$g))]

# plot funnel with all conditional residuals
metafor::funnel(Q2res$resid, sqrt(dat_2$var.g), level=c(90, 95, 99), shade=c("white", "gray55", "gray75"), col=pal, back = "white", refline=0, legend=TRUE, xlab = "Conditional residual", ylab = "Standard error")
```
Because this data set includes both the fitness and resistance effects it's not surprising that small studies are distributed on both sides of the funnel. This does not mean absence of publication bias as negative effects for fitness and positive effects for (-) resistance both would suggest that small studies tend to inflate the negative consequences of environmental stress. For the publication, I suggest we use -g for resistance effects (currently g = infection intensity or prevalence) and/or we use funnel plots for only dataset 1.

### Two step approach to test for publication bias
Following Nakagawa et al. (2021) we conduct a two-step approach to test for publication bias, that can be thought of as a modified Egger's test for multilevel meta analysis. First we include the effect sizes' standard error as the only moderator and including the same random effect structure as in our meta-analysis. If the slope of this moderator is significant, the estimated intercept provides a downwardly biased estimate of the overall meta-analytic effect (Doucouliagos 2012, 2014). In this case, we run a second meta regression with only the effect sizes' variances as moderators. The intercept in this case may still be biased, but less so.

#### Data set 1: fitness effects of environmental stress
```{r dat_1-twostep-1}
# get standard errors of effect sizes 
dat_1$sei <- sqrt(dat_1$var.g)

# meta regression with SE
d1s1 <- rma.mv(
  g ~ 1 + sei,
  V = varcovmat_1_PD$mat,
  random = list(~ 1 | Experiment, ~ 1 | ID),
  data = dat_1,
  method = "REML"
)

d1s1
```

The slope is negative and significant. Small studies report large and negative effect sizes!! Because the slope of sei is significant, variance is a better moderator according to (Doucouliagos 2012, 2014). 

```{r dat_1-twostep-2}
d1s2 <- rma.mv(
  g ~ 1 + dat_1$var.g,
  V = varcovmat_1_PD$mat,
  random = list(~ 1 | Experiment, ~ 1 | ID),
  data = dat_1,
  method = "REML"
)

d1s2 
```

Again, precision effects are significant, suggesting publication bias. Thus, to "account" for potential effects of publication bias, we need to include variance as a moderator.

Including the variance-covariance error matrix within studies
```{r dat_1-PB-adjusted}
Q1.B <-
  rma.mv(
    g ~ Trait.type:Gradient.category + var.g -1,
    V = varcovmat_1_PD$mat,
    random = list( ~ 1 | Experiment, ~ 1 | ID),
    data = dat_1,
    method = "REML"
  )

summary(Q1.B)

forest.default(x= Q1.B$beta, sei =  Q1.B$se, pch = 19,
                annotate=TRUE, showweights=F, header=c("Parameter", "Estimate [95% CI]"), 
                slab = c("variance", "EE:fecundity", "EE:survivorship", "CP:fecundity", "CP:survivorship", "RL:fecundity", "RL:survivorship"), 
               xlab = "Standardised mean difference (Hedge's g)")
```

#### Data set 2: resistance and fitness effects of environmental stress
```{r dat_2-twostep-1}
# get standard errors of effect sizes 
dat_2$sei <- sqrt(dat_2$var.g)

# meta regression with SE
d2s1 <- rma.mv(
  g ~ 1 + sei,
  V = varcovmat_2_PD$mat,
  random = list(~ 1 | Experiment, ~ 1 | ID),
  data = dat_2,
  method = "REML"
)
```

As in data set 1, effects of small studies are dominated by negative effect sizes. Because the slope of sei is significant the variance is a better moderator for the overall effect.
```{r dat_2-twostep-2}
# meta regression with SE
d2s2 <- rma.mv(
  g ~ 1 + dat_2$var.g,
  V = varcovmat_2_PD$mat,
  random = list(~ 1 | Experiment, ~ 1 | ID),
  data = dat_2,
  method = "REML"
)

d2s2
```


```{r dat_2-PB-adjusted}
Q2.B <-
  rma.mv(
    g ~ Trait.type:Gradient.category + var.g -1,
    V = varcovmat_2_PD$mat,
    random = list( ~ 1 | Experiment, ~ 1 | ID),
    data = dat_2,
    method = "REML"
  )

summary(Q2.B)

forest.default(x= Q2.B$beta, sei =  Q2.B$se, pch = 19,
                annotate=TRUE, showweights=F, header=c("Parameter", "Estimate [95% CI]"), 
                slab = c("variance","EE:prevalence", "EE:intensity", "EE:fecundity", "EE:survivorship", "CP:prevalence", "CP:intensity", "CP:fecundity", "CP:survivorship", "RL:prevalence", "RL:intensity", "RL:fecundity", "RL:survivorship"), 
               xlab = "Standardised mean difference (Hedge's g)")
```
#### Contrasts
Wald-type chi-square tests contrasting resistance vs fitness effects on infected hosts.
```{r resistance vs fitness contrasts}
# Environment
# Prevalence vs Fecundity
anova(Q2.B, X=c(0,-1,0,1,0,0,0,0,0,0,0,0,0))
# Prevalence vs Survivorship
anova(Q2.B, X=c(0,-1,0,0,1,0,0,0,0,0,0,0,0))
# Intensity vs Fecundity
anova(Q2.B, X=c(0,0,-1,1,0,0,0,0,0,0,0,0,0))
# Intensity vs Survivorship
anova(Q2.B, X=c(0,0,-1,0,1,0,0,0,0,0,0,0,0))

# Pollution
# Prevalence vs Fecundity
anova(Q2.B, X=c(0,0,0,0,0,-1,0,1,0,0,0,0,0))
# Prevalence vs Survivorship
anova(Q2.B, X=c(0,0,0,0,0,-1,0,0,1,0,0,0,0))
# Intensity vs Fecundity
anova(Q2.B, X=c(0,0,0,0,0,0,-1,1,0,0,0,0,0))
# Intensity vs Survivorship
anova(Q2.B, X=c(0,0,0,0,0,0,-1,0,1,0,0,0,0))

# Resources
# Prevalence vs Fecundity
anova(Q2.B, X=c(0,0,0,0,0,0,0,0,0,-1,0,1,0))
# Prevalence vs Survivorship
anova(Q2.B, X=c(0,0,0,0,0,0,0,0,0,-1,0,0,1))
# Intensity vs Fecundity
anova(Q2.B, X=c(0,0,0,0,0,0,0,0,0,0,-1,1,0))
# Intensity vs Survivorship
anova(Q2.B, X=c(0,0,0,0,0,0,0,0,0,0,-1,0,1))
```

#### Supporting Tables

Table S3
```{r Table S3}
TableS3 <- data.frame(question = rep(c("Q1", "Q2"), each =  2),
                      step = rep(c("Step 1", "Step 2"),2),
                      slope = c(round(d1s1$b[2],3), round(d1s2$b[2],3), round(d2s1$b[2],3), round(d2s2$b[2],3)),
                      se = c(round(d1s1$se[2],3), round(d1s2$se[2],3), round(d2s1$se[2],3), round(d2s2$se[2],3)),
                      pval =c(round(d1s1$pval[2],3), round(d1s2$pval[2],3), round(d2s1$pval[2],3), round(d2s2$pval[2],3)))

TableS3 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

Table S4
```{r Q1 Results table adjusted}
TableS4 <- data.frame(Stressor_type = Table2$Stressor_type,
                     Response_trait = Table2$Response_trait,
                     Overall_mean = Table2$Overall_mean,
                     Lower_95 = Table2$Lower_95,
                     Upper_95 = Table2$Upper_95,
                     P_value = Table2$P_value,
                     Overall_mean_adjusted = round(Q1.B$beta[-1],3),
                     Lower_95_adjusted = round(Q1.B$ci.lb[-1],3),
                     Upper_95_adjusted = round(Q1.B$ci.ub[-1],3),
                     P_value_adjusted = round(Q1.B$pval[-1],3),
                     N_effects = Table2$N_effects,
                     N_experiments = Table2$N_experiments,
                     N_host_taxa = Table2$N_host_taxa)

TableS4 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = T)
```


Table S5
```{r Q2 Results table adjusted}
TableS5 <- data.frame(Stressor_type = Table3$Stressor_type,
                     Response_trait = Table3$Response_trait,
                     Overall_mean = Table3$Overall_mean,
                     Lower_95 = Table3$Lower_95,
                     Upper_95 = Table3$Upper_95,
                     P_value = Table3$P_value,
                     Overall_mean_adjusted = round(Q2.B$beta[-1],3),
                     Lower_95_adjusted = round(Q2.B$ci.lb[-1],3),
                     Upper_95_adjusted = round(Q2.B$ci.ub[-1],3),
                     P_value_adjusted = round(Q2.B$pval[-1],3),
                     N_effects = Table3$N_effects,
                     N_experiments = Table3$N_experiments,
                     N_host_taxa = Table3$N_host_taxa)

TableS5 %>%
  kbl() %>%
  kable_material(c("striped", "hover"), full_width = T)
```
